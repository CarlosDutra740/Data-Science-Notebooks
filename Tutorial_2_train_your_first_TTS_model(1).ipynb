{"cells":[{"cell_type":"markdown","metadata":{"id":"f79d99ef"},"source":["# Train your first üê∏ TTS model üí´\n","\n","### üëã Hello and welcome to Coqui (üê∏) TTS\n","\n","The goal of this notebook is to show you a **typical workflow** for **training** and **testing** a TTS model with üê∏.\n","\n","Let's train a very small model on a very small amount of data so we can iterate quickly.\n","\n","In this notebook, we will:\n","\n","1. Download data and format it for üê∏ TTS.\n","2. Configure the training and testing runs.\n","3. Train a new model.\n","4. Test the model and display its performance.\n","\n","So, let's jump right in!\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21263,"status":"ok","timestamp":1694539843019,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"fa2aec78","outputId":"19b4ee87-f466-4561-bac9-399a7fb36973"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.2.1)\n","\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy\u003e=1.19.*; python_version \u003e= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: TTS in /usr/local/lib/python3.10/dist-packages (0.16.6)\n","Requirement already satisfied: cython==0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.29.30)\n","Requirement already satisfied: scipy\u003e=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.2)\n","Requirement already satisfied: torch\u003e=1.7 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.1+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.2+cu118)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n","Requirement already satisfied: librosa==0.10.0.* in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.0)\n","Requirement already satisfied: inflect==5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (5.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from TTS) (4.66.1)\n","Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.1)\n","Requirement already satisfied: fsspec\u003e=2021.04.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TTS) (23.1)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n","Requirement already satisfied: pysbd in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.4)\n","Requirement already satisfied: umap-learn==0.5.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n","Requirement already satisfied: trainer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.31)\n","Requirement already satisfied: coqpit\u003e=0.0.16 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.17)\n","Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n","Requirement already satisfied: pypinyin in /usr/local/lib/python3.10/dist-packages (from TTS) (0.49.0)\n","Requirement already satisfied: gruut[de,es,fr]==2.2.3 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.3)\n","Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from TTS) (0.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n","Requirement already satisfied: g2pkk\u003e=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.2)\n","Requirement already satisfied: bangla==0.0.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n","Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n","Requirement already satisfied: bnunicodenormalizer==0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.1)\n","Requirement already satisfied: k-diffusion in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.16)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from TTS) (0.6.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from TTS) (4.33.1)\n","Requirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.1)\n","Requirement already satisfied: numpy==1.22.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.22.0)\n","Requirement already satisfied: numba==0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.57.0)\n","Requirement already satisfied: Babel\u003c3.0.0,\u003e=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (2.12.1)\n","Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (1.1.8)\n","Requirement already satisfied: gruut-ipa\u003c1.0,\u003e=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (0.13.0)\n","Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (2.0.0)\n","Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (1.2.0)\n","Requirement already satisfied: networkx\u003c3.0.0,\u003e=2.5.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (2.8.8)\n","Requirement already satisfied: num2words\u003c1.0.0,\u003e=0.5.10 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (0.5.12)\n","Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (0.9.9)\n","Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (2.0.0)\n","Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (2.0.0)\n","Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3-\u003eTTS) (2.0.2)\n","Requirement already satisfied: audioread\u003e=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (3.0.0)\n","Requirement already satisfied: scikit-learn\u003e=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (1.2.2)\n","Requirement already satisfied: joblib\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (1.3.2)\n","Requirement already satisfied: decorator\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (4.4.2)\n","Requirement already satisfied: pooch\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (1.7.0)\n","Requirement already satisfied: soxr\u003e=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (0.3.6)\n","Requirement already satisfied: typing-extensions\u003e=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (4.5.0)\n","Requirement already satisfied: lazy-loader\u003e=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (0.3)\n","Requirement already satisfied: msgpack\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*-\u003eTTS) (1.0.5)\n","Requirement already satisfied: llvmlite\u003c0.41,\u003e=0.40.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.57.0-\u003eTTS) (0.40.1)\n","Requirement already satisfied: pynndescent\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.1-\u003eTTS) (0.5.10)\n","Requirement already satisfied: cffi\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile-\u003eTTS) (1.15.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.7-\u003eTTS) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.7-\u003eTTS) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.7-\u003eTTS) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.7-\u003eTTS) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003e=1.7-\u003eTTS) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003e=1.7-\u003eTTS) (16.0.6)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003eTTS) (23.1.0)\n","Requirement already satisfied: charset-normalizer\u003c4.0,\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003eTTS) (3.2.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003eTTS) (6.0.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003eTTS) (4.0.3)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003eTTS) (1.9.2)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003eTTS) (1.4.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003eTTS) (1.3.1)\n","Requirement already satisfied: Werkzeug\u003e=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask-\u003eTTS) (2.3.7)\n","Requirement already satisfied: itsdangerous\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from flask-\u003eTTS) (2.1.2)\n","Requirement already satisfied: click\u003e=8.0 in /usr/local/lib/python3.10/dist-packages (from flask-\u003eTTS) (8.1.7)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.22.0)\n","Requirement already satisfied: clean-fid in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.1.35)\n","Requirement already satisfied: clip-anytorch in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (2.5.2)\n","Requirement already satisfied: jsonmerge in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (1.9.2)\n","Requirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.7.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (9.4.0)\n","Requirement already satisfied: resize-right in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.0.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.19.3)\n","Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.2.3)\n","Requirement already satisfied: torchsde in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.2.5)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.15.2+cu118)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from k-diffusion-\u003eTTS) (0.15.10)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eTTS) (1.1.0)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eTTS) (0.11.0)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eTTS) (4.42.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eTTS) (1.4.5)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eTTS) (3.1.1)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eTTS) (2.8.2)\n","Requirement already satisfied: regex\u003e=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk-\u003eTTS) (2023.6.3)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003eTTS) (2023.3.post1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer-\u003eTTS) (5.9.5)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer-\u003eTTS) (2.13.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003eTTS) (0.17.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers-\u003eTTS) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003eTTS) (0.13.3)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003eTTS) (0.3.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi\u003e=1.0-\u003esoundfile-\u003eTTS) (2.21)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0-\u003egruut[de,es,fr]==2.2.3-\u003eTTS) (5.0.1)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.7-\u003eTTS) (2.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0-\u003egruut[de,es,fr]==2.2.3-\u003eTTS) (1.16.0)\n","Requirement already satisfied: docopt\u003e=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words\u003c1.0.0,\u003e=0.5.10-\u003egruut[de,es,fr]==2.2.3-\u003eTTS) (0.6.2)\n","Requirement already satisfied: platformdirs\u003e=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch\u003e=1.0-\u003elibrosa==0.10.0.*-\u003eTTS) (3.10.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers-\u003eTTS) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers-\u003eTTS) (2.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers-\u003eTTS) (2023.7.22)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.20.0-\u003elibrosa==0.10.0.*-\u003eTTS) (3.2.0)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip-anytorch-\u003ek-diffusion-\u003eTTS) (6.1.1)\n","Requirement already satisfied: jsonschema\u003e2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge-\u003ek-diffusion-\u003eTTS) (4.19.0)\n","Requirement already satisfied: imageio\u003e=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image-\u003ek-diffusion-\u003eTTS) (2.31.3)\n","Requirement already satisfied: tifffile\u003e=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image-\u003ek-diffusion-\u003eTTS) (2023.8.30)\n","Requirement already satisfied: PyWavelets\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image-\u003ek-diffusion-\u003eTTS) (1.4.1)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.7-\u003eTTS) (1.3.0)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (1.4.0)\n","Requirement already satisfied: grpcio\u003e=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (1.57.0)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib\u003c1.1,\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (1.0.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (3.4.4)\n","Requirement already satisfied: protobuf\u003e=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (3.20.3)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (0.7.1)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003etrainer-\u003eTTS) (0.41.2)\n","Requirement already satisfied: boltons\u003e=20.2.1 in /usr/local/lib/python3.10/dist-packages (from torchsde-\u003ek-diffusion-\u003eTTS) (23.0.0)\n","Requirement already satisfied: trampoline\u003e=0.1.2 in /usr/local/lib/python3.10/dist-packages (from torchsde-\u003ek-diffusion-\u003eTTS) (0.1.2)\n","Requirement already satisfied: GitPython!=3.1.29,\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb-\u003ek-diffusion-\u003eTTS) (3.1.36)\n","Requirement already satisfied: sentry-sdk\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb-\u003ek-diffusion-\u003eTTS) (1.30.0)\n","Requirement already satisfied: docker-pycreds\u003e=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb-\u003ek-diffusion-\u003eTTS) (0.4.0)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb-\u003ek-diffusion-\u003eTTS) (0.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb-\u003ek-diffusion-\u003eTTS) (1.3.2)\n","Requirement already satisfied: appdirs\u003e=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb-\u003ek-diffusion-\u003eTTS) (1.4.4)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,\u003e=1.0.0-\u003ewandb-\u003ek-diffusion-\u003eTTS) (4.0.10)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003etrainer-\u003eTTS) (5.3.1)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003etrainer-\u003eTTS) (0.3.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003etrainer-\u003eTTS) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c1.1,\u003e=0.5-\u003etensorboard-\u003etrainer-\u003eTTS) (1.3.1)\n","Requirement already satisfied: jsonschema-specifications\u003e=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e2.4.0-\u003ejsonmerge-\u003ek-diffusion-\u003eTTS) (2023.7.1)\n","Requirement already satisfied: referencing\u003e=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e2.4.0-\u003ejsonmerge-\u003ek-diffusion-\u003eTTS) (0.30.2)\n","Requirement already satisfied: rpds-py\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e2.4.0-\u003ejsonmerge-\u003ek-diffusion-\u003eTTS) (0.10.2)\n","Requirement already satisfied: wcwidth\u003e=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy-\u003eclip-anytorch-\u003ek-diffusion-\u003eTTS) (0.2.6)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003eGitPython!=3.1.29,\u003e=1.0.0-\u003ewandb-\u003ek-diffusion-\u003eTTS) (5.0.0)\n","Requirement already satisfied: pyasn1\u003c0.6.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003etrainer-\u003eTTS) (0.5.0)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c1.1,\u003e=0.5-\u003etensorboard-\u003etrainer-\u003eTTS) (3.2.2)\n","\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy\u003e=1.19.*; python_version \u003e= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["## Install Coqui TTS\n","! pip install -U pip\n","! pip install TTS"]},{"cell_type":"markdown","metadata":{"id":"be5fe49c"},"source":["## ‚úÖ Data Preparation\n","\n","### **First things first**: we need some data.\n","\n","We're training a Text-to-Speech model, so we need some _text_ and we need some _speech_. Specificially, we want _transcribed speech_. The speech must be divided into audio clips and each clip needs transcription. More details about data requirements such as recording characteristics, background noise and vocabulary coverage can be found in the [üê∏TTS documentation](https://tts.readthedocs.io/en/latest/formatting_your_dataset.html).\n","\n","If you have a single audio file and you need to **split** it into clips. It is also important to use a lossless audio file format to prevent compression artifacts. We recommend using **wav** file format.\n","\n","The data format we will be adopting for this tutorial is taken from the widely-used  **LJSpeech** dataset, where **waves** are collected under a folder:\n","\n","\u003cspan style=\"color:purple;font-size:15px\"\u003e\n","/wavs\u003cbr /\u003e\n"," \u0026emsp;| - audio1.wav\u003cbr /\u003e\n"," \u0026emsp;| - audio2.wav\u003cbr /\u003e\n"," \u0026emsp;| - audio3.wav\u003cbr /\u003e\n","  ...\u003cbr /\u003e\n","\u003c/span\u003e\n","\n","and a **metadata.csv** file will have the audio file name in parallel to the transcript, delimited by `|`:\n","\n","\u003cspan style=\"color:purple;font-size:15px\"\u003e\n","# metadata.csv \u003cbr /\u003e\n","audio1|This is my sentence. \u003cbr /\u003e\n","audio2|This is maybe my sentence. \u003cbr /\u003e\n","audio3|This is certainly my sentence. \u003cbr /\u003e\n","audio4|Let this be your sentence. \u003cbr /\u003e\n","...\n","\u003c/span\u003e\n","\n","In the end, we should have the following **folder structure**:\n","\n","\u003cspan style=\"color:purple;font-size:15px\"\u003e\n","/MyTTSDataset \u003cbr /\u003e\n","\u0026emsp;| \u003cbr /\u003e\n","\u0026emsp;| -\u003e metadata.csv\u003cbr /\u003e\n","\u0026emsp;| -\u003e /wavs\u003cbr /\u003e\n","\u0026emsp;\u0026emsp;| -\u003e audio1.wav\u003cbr /\u003e\n","\u0026emsp;\u0026emsp;| -\u003e audio2.wav\u003cbr /\u003e\n","\u0026emsp;\u0026emsp;| ...\u003cbr /\u003e\n","\u003c/span\u003e"]},{"cell_type":"markdown","metadata":{"id":"69501a10-3b53-4e75-ae66-90221d6f2271"},"source":["üê∏TTS already provides tooling for the _LJSpeech_. if you use the same format, you can start training your models right away. \u003cbr /\u003e\n","\n","After you collect and format your dataset, you need to check two things. Whether you need a **_formatter_** and a **_text_cleaner_**. \u003cbr /\u003e The **_formatter_** loads the text file (created above) as a list and the **_text_cleaner_** performs a sequence of text normalization operations that converts the raw text into the spoken representation (e.g. converting numbers to text, acronyms, and symbols to the spoken format).\n","\n","If you use a different dataset format then the LJSpeech or the other public datasets that üê∏TTS supports, then you need to write your own **_formatter_** and  **_text_cleaner_**."]},{"cell_type":"markdown","metadata":{"id":"e7f226c8-4e55-48fa-937b-8415d539b17c"},"source":["## ‚è≥Ô∏è Loading your dataset\n","Load one of the dataset supported by üê∏TTS.\n","\n","We will start by defining dataset config and setting LJSpeech as our target dataset and define its path.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3715,"status":"ok","timestamp":1694539846726,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"b3cb0191-b8fc-4158-bd26-8423c2a8ba66"},"outputs":[],"source":["import os\n","\n","# BaseDatasetConfig: defines name, formatter and path of the dataset.\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig\n","\n","output_path = \"tts_train_dir\"\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514268,"status":"ok","timestamp":1694540360990,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"ae6b7019-3685-4b48-8917-c152e288d7e3","outputId":"96eb92f5-d16e-4832-d71e-eb3f52f57b1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-09-12 17:30:45--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n","Resolving data.keithito.com (data.keithito.com)... 24.199.73.137\n","Connecting to data.keithito.com (data.keithito.com)|24.199.73.137|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2748572632 (2.6G) [text/plain]\n","Saving to: ‚Äòtts_train_dir/LJSpeech-1.1.tar.bz2‚Äô\n","\n","tts_train_dir/LJSpe 100%[===================\u003e]   2.56G  35.4MB/s    in 97s     \n","\n","2023-09-12 17:32:23 (26.9 MB/s) - ‚Äòtts_train_dir/LJSpeech-1.1.tar.bz2‚Äô saved [2748572632/2748572632]\n","\n"]}],"source":["# Download and extract LJSpeech dataset.\n","\n","!wget -O $output_path/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n","!tar -xf $output_path/LJSpeech-1.1.tar.bz2 -C $output_path"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1694540360991,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"76cd3ab5-6387-45f1-b488-24734cc1beb5"},"outputs":[],"source":["dataset_config = BaseDatasetConfig(\n","    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"LJSpeech-1.1/\")\n",")"]},{"cell_type":"markdown","metadata":{"id":"ae82fd75"},"source":["## ‚úÖ Train a new model\n","\n","Let's kick off a training run üöÄüöÄüöÄ.\n","\n","Deciding on the model architecture you'd want to use is based on your needs and available resources. Each model architecture has it's pros and cons that define the run-time efficiency and the voice quality.\n","We have many recipes under `TTS/recipes/` that provide a good starting point. For this tutorial, we will be using `GlowTTS`."]},{"cell_type":"markdown","metadata":{"id":"f5876e46-2aee-4bcf-b6b3-9e3c535c553f"},"source":["We will begin by initializing the model training configuration."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1694540360992,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"5483ca28-39d6-49f8-a18e-4fb53c50ad84"},"outputs":[],"source":["# GlowTTSConfig: all model related values for training, validating and testing.\n","from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n","config = GlowTTSConfig(\n","    batch_size=32,\n","    eval_batch_size=16,\n","    num_loader_workers=4,\n","    num_eval_loader_workers=4,\n","    run_eval=True,\n","    test_delay_epochs=-1,\n","    epochs=5,\n","    text_cleaner=\"phoneme_cleaners\",\n","    use_phonemes=True,\n","    phoneme_language=\"en-us\",\n","    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n","    print_step=25,\n","    print_eval=False,\n","    mixed_precision=True,\n","    output_path=output_path,\n","    datasets=[dataset_config],\n","    save_step=1000,\n",")"]},{"cell_type":"markdown","metadata":{"id":"b93ed377-80b7-447b-bd92-106bffa777ee"},"source":["Next we will initialize the audio processor which is used for feature extraction and audio I/O."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3277,"status":"ok","timestamp":1694540364263,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"b1b12f61-f851-4565-84dd-7640947e04ab","outputId":"c41ecb42-674e-49b0-8ea5-f198f683731e"},"outputs":[{"name":"stdout","output_type":"stream","text":[" \u003e Setting up Audio Processor...\n"," | \u003e sample_rate:22050\n"," | \u003e resample:False\n"," | \u003e num_mels:80\n"," | \u003e log_func:np.log10\n"," | \u003e min_level_db:-100\n"," | \u003e frame_shift_ms:None\n"," | \u003e frame_length_ms:None\n"," | \u003e ref_level_db:20\n"," | \u003e fft_size:1024\n"," | \u003e power:1.5\n"," | \u003e preemphasis:0.0\n"," | \u003e griffin_lim_iters:60\n"," | \u003e signal_norm:True\n"," | \u003e symmetric_norm:True\n"," | \u003e mel_fmin:0\n"," | \u003e mel_fmax:None\n"," | \u003e pitch_fmin:1.0\n"," | \u003e pitch_fmax:640.0\n"," | \u003e spec_gain:20.0\n"," | \u003e stft_pad_mode:reflect\n"," | \u003e max_norm:4.0\n"," | \u003e clip_norm:True\n"," | \u003e do_trim_silence:True\n"," | \u003e trim_db:45\n"," | \u003e do_sound_norm:False\n"," | \u003e do_amp_to_db_linear:True\n"," | \u003e do_amp_to_db_mel:True\n"," | \u003e do_rms_norm:False\n"," | \u003e db_level:None\n"," | \u003e stats_path:None\n"," | \u003e base:10\n"," | \u003e hop_length:256\n"," | \u003e win_length:1024\n"]}],"source":["from TTS.utils.audio import AudioProcessor\n","ap = AudioProcessor.init_from_config(config)\n","# Modify sample rate if for a custom audio dataset:\n","# ap.sample_rate = 22050\n"]},{"cell_type":"markdown","metadata":{"id":"1d461683-b05e-403f-815f-8007bda08c38"},"source":["Next we will initialize the tokenizer which is used to convert text to sequences of token IDs.  If characters are not defined in the config, default characters are passed to the config."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3249,"status":"ok","timestamp":1694540367502,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"014879b7-f18d-44c0-b24a-e10f8002113a"},"outputs":[],"source":["from TTS.tts.utils.text.tokenizer import TTSTokenizer\n","tokenizer, config = TTSTokenizer.init_from_config(config)"]},{"cell_type":"markdown","metadata":{"id":"df3016e1-9e99-4c4f-94e3-fa89231fd978"},"source":["Next we will load data samples. Each sample is a list of ```[text, audio_file_path, speaker_name]```. You can define your custom sample loader returning the list of samples."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1580,"status":"ok","timestamp":1694540369078,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"cadd6ada-c8eb-4f79-b8fe-6d72850af5a7","outputId":"f5405a53-2b8e-41b4-8ddd-b39aafb8ec48"},"outputs":[{"name":"stdout","output_type":"stream","text":[" | \u003e Found 13100 files in /content/tts_train_dir/LJSpeech-1.1\n"]}],"source":["from TTS.tts.datasets import load_tts_samples\n","train_samples, eval_samples = load_tts_samples(\n","    dataset_config,\n","    eval_split=True,\n","    eval_split_max_size=config.eval_split_max_size,\n","    eval_split_size=config.eval_split_size,\n",")"]},{"cell_type":"markdown","metadata":{"id":"db8b451e-1fe1-4aa3-b69e-ab22b925bd19"},"source":["Now we're ready to initialize the model.\n","\n","Models take a config object and a speaker manager as input. Config defines the details of the model like the number of layers, the size of the embedding, etc. Speaker manager is used by multi-speaker models."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2051,"status":"ok","timestamp":1694540371126,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"ac2ffe3e-ad0c-443e-800c-9b076ee811b4"},"outputs":[],"source":["from TTS.tts.models.glow_tts import GlowTTS\n","model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"]},{"cell_type":"markdown","metadata":{"id":"e2832c56-889d-49a6-95b6-eb231892ecc6"},"source":["Trainer provides a generic API to train all the üê∏TTS models with all its perks like mixed-precision training, distributed training, etc."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5640,"status":"ok","timestamp":1694540376760,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"0f609945-4fe0-4d0d-b95e-11d7bfb63ebe","outputId":"0dc2a7c6-0cdd-4c06-9e46-14c7ecb8f0d9"},"outputs":[{"name":"stderr","output_type":"stream","text":[" \u003e Training Environment:\n"," | \u003e Backend: Torch\n"," | \u003e Mixed precision: True\n"," | \u003e Precision: fp16\n"," | \u003e Num. of CPUs: 2\n"," | \u003e Num. of Torch Threads: 1\n"," | \u003e Torch seed: 54321\n"," | \u003e Torch CUDNN: True\n"," | \u003e Torch CUDNN deterministic: False\n"," | \u003e Torch CUDNN benchmark: False\n"," | \u003e Torch TF32 MatMul: False\n"," \u003e Start Tensorboard: tensorboard --logdir=tts_train_dir/run-September-12-2023_05+39PM-0000000\n","\n"," \u003e Model has 28610257 parameters\n"]}],"source":["from trainer import Trainer, TrainerArgs\n","trainer = Trainer(\n","    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",")"]},{"cell_type":"markdown","metadata":{"id":"5b320831-dd83-429b-bb6a-473f9d49d321"},"source":["### AND... 3,2,1... START TRAINING üöÄüöÄüöÄ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"d4c07f99-3d1d-4bea-801e-9f33bbff0e9f"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\u001b[4m\u001b[1m \u003e EPOCH: 0/5\u001b[0m\n"," --\u003e tts_train_dir/run-September-12-2023_05+39PM-0000000\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\n","\u001b[1m \u003e TRAINING (2023-09-12 17:39:36) \u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","\u003e DataLoader initialization\n","| \u003e Tokenizer:\n","\t| \u003e add_blank: False\n","\t| \u003e use_eos_bos: False\n","\t| \u003e use_phonemes: True\n","\t| \u003e phonemizer:\n","\t\t| \u003e phoneme language: en-us\n","\t\t| \u003e phoneme backend: gruut\n","| \u003e Number of instances : 12969\n"," | \u003e Preprocessing samples\n"," | \u003e Max text length: 188\n"," | \u003e Min text length: 13\n"," | \u003e Avg text length: 100.90014650319993\n"," | \n"," | \u003e Max audio length: 222643.0\n"," | \u003e Min audio length: 24499.0\n"," | \u003e Avg audio length: 144984.29755570978\n"," | \u003e Num. instances discarded samples: 0\n"," | \u003e Batch group size: 0.\n"]},{"name":"stderr","output_type":"stream","text":["\n","\u001b[1m   --\u003e TIME: 2023-09-12 17:43:51 -- STEP: 0/406 -- GLOBAL_STEP: 0\u001b[0m\n","     | \u003e current_lr: 2.5e-07 \n","     | \u003e step_time: 249.9801  (249.98010182380676)\n","     | \u003e loader_time: 5.4384  (5.438424825668335)\n","\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"]},{"name":"stdout","output_type":"stream","text":["tÕ° Éif …πo äli b…™livd √∞√¶t √∞e…™ w äd,\n"," [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n"]},{"name":"stderr","output_type":"stream","text":[" [!] `train_step()` retuned `None` outputs. Skipping training step.\n"]},{"name":"stdout","output_type":"stream","text":["√¶nd s…ôbdÕ° í…õkt t…ô …™ks…õp É…ônz.\n"," [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n"]},{"name":"stderr","output_type":"stream","text":[" [!] `train_step()` retuned `None` outputs. Skipping training step.\n"]},{"name":"stdout","output_type":"stream","text":["w…õn √∞…ô dÕ° í ådÕ° í …ôsumd √∞…ô bl√¶k k√¶p\n"," [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n"]},{"name":"stderr","output_type":"stream","text":[" [!] `train_step()` retuned `None` outputs. Skipping training step.\n"]},{"name":"stdout","output_type":"stream","text":["w ån …™mpl…î…™i, dÕ° í√¶k do ä…öti,\n"," [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n"]},{"name":"stderr","output_type":"stream","text":[" [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"]}],"source":["trainer.fit()"]},{"cell_type":"markdown","metadata":{"id":"4cff0c40-2734-40a6-a905-e945a9fb3e98"},"source":["#### üöÄ Run the Tensorboard. üöÄ\n","On the notebook and Tensorboard, you can monitor the progress of your model. Also Tensorboard provides certain figures and sample outputs."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3967,"status":"ok","timestamp":1694539536884,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"5a85cd3b-1646-40ad-a6c2-49323e08eeec","outputId":"5a6b6571-9e35-4354-8276-218fd37cac1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.13.0)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio\u003e=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.57.0)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib\u003c1.1,\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.4)\n","Requirement already satisfied: numpy\u003e=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.0)\n","Requirement already satisfied: protobuf\u003e=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.7)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.41.2)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard) (5.3.1)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard) (0.3.0)\n","Requirement already satisfied: six\u003e=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard) (1.16.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c1.1,\u003e=0.5-\u003etensorboard) (1.3.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard) (3.2.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard) (2.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard) (2023.7.22)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard) (2.1.3)\n","Requirement already satisfied: pyasn1\u003c0.6.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard) (0.5.0)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c1.1,\u003e=0.5-\u003etensorboard) (3.2.2)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n","    from tensorboard.compat import notf  # noqa: F401\n","ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/tensorboard\", line 8, in \u003cmodule\u003e\n","    sys.exit(run_main())\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/main.py\", line 39, in run_main\n","    main_lib.global_init()\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/main_lib.py\", line 40, in global_init\n","    if getattr(tf, \"__version__\", \"stub\") == \"stub\":\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 65, in __getattr__\n","    return getattr(load_once(self), attr_name)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 97, in wrapper\n","    cache[arg] = f(arg)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 50, in load_once\n","    module = load_fn()\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 45, in tf\n","    import tensorflow\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 38, in \u003cmodule\u003e\n","    from tensorflow.python.tools import module_util as _module_util\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py\", line 45, in \u003cmodule\u003e\n","    from tensorflow.python.feature_column import feature_column_lib as feature_column\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/feature_column/feature_column_lib.py\", line 18, in \u003cmodule\u003e\n","    from tensorflow.python.feature_column.feature_column import *\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 143, in \u003cmodule\u003e\n","    from tensorflow.python.layers import base\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/layers/base.py\", line 16, in \u003cmodule\u003e\n","    from tensorflow.python.keras.legacy_tf_layers import base\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/__init__.py\", line 25, in \u003cmodule\u003e\n","    from tensorflow.python.keras import models\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/models.py\", line 20, in \u003cmodule\u003e\n","    from tensorflow.python.keras import metrics as metrics_module\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/metrics.py\", line 35, in \u003cmodule\u003e\n","    from tensorflow.python.keras import activations\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/activations.py\", line 18, in \u003cmodule\u003e\n","    from tensorflow.python.keras.layers import advanced_activations\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/layers/__init__.py\", line 22, in \u003cmodule\u003e\n","    from tensorflow.python.keras.engine.input_layer import Input\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 24, in \u003cmodule\u003e\n","    from tensorflow.python.keras.engine import base_layer\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 56, in \u003cmodule\u003e\n","    from tensorflow.python.keras.saving.saved_model import layer_serialization\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 20, in \u003cmodule\u003e\n","    from tensorflow.python.keras.saving.saved_model import save_impl\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 34, in \u003cmodule\u003e\n","    from tensorflow.python.keras.saving.saved_model import load as keras_load\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 45, in \u003cmodule\u003e\n","    from tensorflow.python.saved_model import load as tf_load\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\", line 51, in \u003cmodule\u003e\n","    from tensorflow.python.saved_model import load_v1_in_v2\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load_v1_in_v2.py\", line 29, in \u003cmodule\u003e\n","    from tensorflow.python.saved_model import loader_impl\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 26, in \u003cmodule\u003e\n","    from tensorflow.core.protobuf import saved_model_pb2\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 1027, in _find_and_load\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 1006, in _find_and_load_unlocked\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 688, in _load_unlocked\n","  File \"\u003cfrozen importlib._bootstrap_external\u003e\", line 879, in exec_module\n","  File \"\u003cfrozen importlib._bootstrap_external\u003e\", line 1012, in get_code\n","  File \"\u003cfrozen importlib._bootstrap_external\u003e\", line 672, in _compile_bytecode\n","KeyboardInterrupt\n","^C\n"]}],"source":["!pip install tensorboard\n","!tensorboard --logdir=tts_train_dir"]},{"cell_type":"markdown","metadata":{"id":"9f6dc959"},"source":["## ‚úÖ Test the model\n","\n","We made it! üôå\n","\n","Let's kick off the testing run, which displays performance metrics.\n","\n","We're committing the cardinal sin of ML üòà (aka - testing on our training data) so you don't want to deploy this model into production. In this notebook we're focusing on the workflow itself, so it's forgivable üòá\n","\n","You can see from the test output that our tiny model has overfit to the data, and basically memorized this one sentence.\n","\n","When you start training your own models, make sure your testing data doesn't include your training data üòÖ"]},{"cell_type":"markdown","metadata":{"id":"99fada7a-592f-4a09-9369-e6f3d82de3a0"},"source":["Let's get the latest saved checkpoint."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dd47ed5-da8e-4bf9-b524-d686630d6961"},"outputs":[],"source":["import glob, os\n","output_path = \"tts_train_dir\"\n","ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n","configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dd42bc7a"},"outputs":[],"source":[" !tts --text \"Text for TTS\" \\\n","      --model_path $test_ckpt \\\n","      --config_path $test_config \\\n","      --out_path out.wav"]},{"cell_type":"markdown","metadata":{"id":"81cbcb3f-d952-469b-a0d8-8941cd7af670"},"source":["## üì£ Listen to the synthesized wave üì£"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0000bd6-6763-4a10-a74d-911dd08ebcff"},"outputs":[],"source":["import IPython\n","IPython.display.Audio(\"out.wav\")"]},{"cell_type":"markdown","metadata":{"id":"13914401-cad1-494a-b701-474e52829138"},"source":["## üéâ Congratulations! üéâ You now have trained your first TTS model!\n","Follow up with the next tutorials to learn more advanced material."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}