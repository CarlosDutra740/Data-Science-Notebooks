{"cells":[{"cell_type":"markdown","source":["Carlos Henrique Amorim Dutra\n"],"metadata":{"id":"OSNs_nlc7mw4"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"beagAGw5t5bK","executionInfo":{"status":"ok","timestamp":1695554680023,"user_tz":180,"elapsed":42020,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[],"source":["%%capture\n","# Local installation\n","!git clone https://github.com/speechbrain/speechbrain/\n","%cd /content/speechbrain/\n","!pip install -r requirements.txt\n","!pip install -e ."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UkzpTp0tk1g9","executionInfo":{"status":"ok","timestamp":1695554687593,"user_tz":180,"elapsed":7575,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[],"source":["import speechbrain as sb"]},{"cell_type":"code","source":["%cd /content/speechbrain/templates/speaker_id\n","!python train.py train.yaml --number_of_epochs=15"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-IqPu5Q70lR","executionInfo":{"status":"ok","timestamp":1695555985768,"user_tz":180,"elapsed":8904,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}},"outputId":"84e5b4da-3aab-45e7-b1b8-61900ae5acd0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/speechbrain/templates/speaker_id\n","./data/rirs_noises.zip exists. Skipping download\n","speechbrain.core - Beginning experiment!\n","speechbrain.core - Experiment folder: ./results/speaker_id/1986\n","mini_librispeech_prepare - Preparation completed in previous run, skipping.\n","speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n","speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n","speechbrain.core - 4.5M trainable parameters in SpkIdBrain\n","speechbrain.utils.checkpoints - Loading a checkpoint from results/speaker_id/1986/save/CKPT+2023-09-24+11-45-19+00\n","speechbrain.utils.checkpoints - Loading a checkpoint from results/speaker_id/1986/save/CKPT+2023-09-24+11-45-19+00\n","  0% 0/10 [00:00<?, ?it/s]/content/speechbrain/speechbrain/dataio/encoder.py:722: UserWarning: CategoricalEncoder.expect_len was never called: assuming category count of 28 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n","  warnings.warn(\n","100% 10/10 [00:02<00:00,  3.57it/s]\n","speechbrain.utils.train_logger - Epoch loaded: 15 - test loss: 4.07e-03, test error: 0.00e+00\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jwoN5Vq0dFYe","executionInfo":{"status":"ok","timestamp":1695555931348,"user_tz":180,"elapsed":245,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[],"source":["# Create folder for best model\n","!mkdir /content/best_model/\n","\n","# Copy label encoder\n","!cp results/speaker_id/1986/save/label_encoder.txt /content/best_model/\n","\n","# Copy best model\n","!cp \"`ls -td results/speaker_id/1986/save/CKPT* | tail -1`\"/* /content/best_model/"]},{"cell_type":"code","source":[],"metadata":{"id":"kywWMFGg8x6w"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvvY0dCbx5Sv","outputId":"d44c6746-b001-458b-fa74-642f7fe44378","executionInfo":{"status":"ok","timestamp":1695556021614,"user_tz":180,"elapsed":615,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-31.8672, -35.2024, -25.7931,  ..., -21.0045, -12.4279, -21.5266]])\n","tensor([-1.1278])\n","tensor([2710])\n","['id10892']\n"]}],"source":["import torchaudio\n","from speechbrain.pretrained import EncoderClassifier\n","\n","classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\")\n","signal, fs =torchaudio.load('/content/speechbrain/tests/samples/single-mic/example1.wav')\n","\n","# Compute speaker embeddings\n","embeddings = classifier.encode_batch(signal)\n","\n","# Perform classification\n","output_probs, score, index, text_lab = classifier.classify_batch(signal)\n","\n","# Posterior log probabilities\n","print(output_probs)\n","\n","# Score (i.e, max log posteriors)\n","print(score)\n","\n","# Index of the predicted speaker\n","print(index)\n","\n","# Text label of the predicted speaker\n","print(text_lab)\n"]},{"cell_type":"markdown","metadata":{"id":"LAZci6oSzdh_"},"source":["For those of you interested in speaker verification, we also created an inference interface called `SpeakerRecognition`:"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-enSWy_z8CF","outputId":"e4e49035-4f7a-4bb7-9338-ae8c6bdccda5","executionInfo":{"status":"ok","timestamp":1695556029781,"user_tz":180,"elapsed":1581,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.1799])\n","tensor([False])\n"]}],"source":["from speechbrain.pretrained import SpeakerRecognition\n","verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n","\n","file1 = '/content/speechbrain/tests/samples/single-mic/example1.wav'\n","file2 = '/content/speechbrain/tests/samples/single-mic/example2.flac'\n","\n","score, prediction = verification.verify_files(file1, file2)\n","\n","print(score)\n","print(prediction) # True = same speaker, False=Different speakers"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ys41HanSaCys","outputId":"c8ce6e77-e7aa-4686-dcc8-dbcfa5df72f9","executionInfo":{"status":"ok","timestamp":1695556033985,"user_tz":180,"elapsed":240,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/best_model/hparams_inference.yaml\n"]}],"source":["%%writefile /content/best_model/hparams_inference.yaml\n","\n","# #################################\n","# Basic inference parameters for speaker-id. We have first a network that\n","# computes some embeddings. On the top of that, we employ a classifier.\n","#\n","# Author:\n","#  * Mirco Ravanelli 2021\n","# #################################\n","\n","# pretrain folders:\n","pretrained_path: /content/best_model/\n","\n","\n","# Model parameters\n","n_mels: 23\n","sample_rate: 16000\n","n_classes: 28 # In this case, we have 28 speakers\n","emb_dim: 512 # dimensionality of the embeddings\n","\n","# Feature extraction\n","compute_features: !new:speechbrain.lobes.features.Fbank\n","    n_mels: !ref <n_mels>\n","\n","# Mean and std normalization of the input features\n","mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n","    norm_type: sentence\n","    std_norm: False\n","\n","# To design a custom model, either just edit the simple CustomModel\n","# class that's listed here, or replace this `!new` call with a line\n","# pointing to a different file you've defined.\n","embedding_model: !new:custom_model.Xvector\n","    in_channels: !ref <n_mels>\n","    activation: !name:torch.nn.LeakyReLU\n","    tdnn_blocks: 5\n","    tdnn_channels: [512, 512, 512, 512, 1500]\n","    tdnn_kernel_sizes: [5, 3, 3, 1, 1]\n","    tdnn_dilations: [1, 2, 3, 1, 1]\n","    lin_neurons: !ref <emb_dim>\n","\n","classifier: !new:custom_model.Classifier\n","    input_shape: [null, null, !ref <emb_dim>]\n","    activation: !name:torch.nn.LeakyReLU\n","    lin_blocks: 1\n","    lin_neurons: !ref <emb_dim>\n","    out_neurons: !ref <n_classes>\n","\n","label_encoder: !new:speechbrain.dataio.encoder.CategoricalEncoder\n","\n","# Objects in \"modules\" dict will have their parameters moved to the correct\n","# device, as well as having train()/eval() called on them by the Brain class.\n","modules:\n","    compute_features: !ref <compute_features>\n","    embedding_model: !ref <embedding_model>\n","    classifier: !ref <classifier>\n","    mean_var_norm: !ref <mean_var_norm>\n","\n","pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n","    loadables:\n","        embedding_model: !ref <embedding_model>\n","        classifier: !ref <classifier>\n","        label_encoder: !ref <label_encoder>\n","    paths:\n","        embedding_model: !ref <pretrained_path>/embedding_model.ckpt\n","        classifier: !ref <pretrained_path>/classifier.ckpt\n","        label_encoder: !ref <pretrained_path>/label_encoder.txt\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fT8ON1iiuQY","outputId":"bdcf5bad-bc81-48b9-9ac1-140d0918337c","executionInfo":{"status":"ok","timestamp":1695556038087,"user_tz":180,"elapsed":739,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Target: 5789, Predicted: 5789\n","Target: 460, Predicted: 460\n"]}],"source":["from speechbrain.pretrained import EncoderClassifier\n","\n","classifier = EncoderClassifier.from_hparams(source=\"/content/best_model/\", hparams_file='hparams_inference.yaml', savedir=\"/content/best_model/\")\n","\n","# Perform classification\n","audio_file = 'data/LibriSpeech/train-clean-5/5789/70653/5789-70653-0036.flac'\n","signal, fs = torchaudio.load(audio_file) # test_speaker: 5789\n","output_probs, score, index, text_lab = classifier.classify_batch(signal)\n","print('Target: 5789, Predicted: ' + text_lab[0])\n","\n","# Another speaker\n","audio_file = 'data/LibriSpeech/train-clean-5/460/172359/460-172359-0012.flac'\n","signal, fs =torchaudio.load(audio_file) # test_speaker: 460\n","output_probs, score, index, text_lab = classifier.classify_batch(signal)\n","print('Target: 460, Predicted: ' + text_lab[0])\n","\n","# And if you want to extract embeddings...\n","embeddings = classifier.encode_batch(signal)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yM19Dn-B7fbV","executionInfo":{"status":"ok","timestamp":1695556097783,"user_tz":180,"elapsed":15207,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}},"outputId":"fae2a0e7-e677-4fc1-efb0-d19131b87e56"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/speechbrain/templates/speaker_id\n","Traceback (most recent call last):\n","  File \"/content/speechbrain/templates/speaker_id/train.py\", line 290, in <module>\n","    hparams = load_hyperpyyaml(fin, overrides)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 157, in load_hyperpyyaml\n","    yaml_stream = resolve_references(yaml_stream, overrides, overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 316, in resolve_references\n","    recursive_update(preview, overrides, must_match=overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 778, in recursive_update\n","    raise KeyError(f\"Override '{k}' not found in: {[key for key in d.keys()]}\")\n","KeyError: \"Override 'rnn_layers' not found in: ['seed', '__set_seed', 'data_folder', 'output_folder', 'save_folder', 'train_log', 'rir_folder', 'train_annotation', 'valid_annotation', 'test_annotation', 'split_ratio', 'skip_prep', 'train_logger', 'error_stats', 'ckpt_interval_minutes', 'n_mels', 'sample_rate', 'number_of_epochs', 'batch_size', 'lr_start', 'lr_final', 'n_classes', 'emb_dim', 'dataloader_options', 'env_corrupt', 'augmentation', 'compute_features', 'mean_var_norm', 'embedding_model', 'classifier', 'epoch_counter', 'modules', 'opt_class', 'lr_annealing', 'checkpointer']\"\n","Traceback (most recent call last):\n","  File \"/content/speechbrain/templates/speaker_id/train.py\", line 290, in <module>\n","    hparams = load_hyperpyyaml(fin, overrides)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 157, in load_hyperpyyaml\n","    yaml_stream = resolve_references(yaml_stream, overrides, overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 316, in resolve_references\n","    recursive_update(preview, overrides, must_match=overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 778, in recursive_update\n","    raise KeyError(f\"Override '{k}' not found in: {[key for key in d.keys()]}\")\n","KeyError: \"Override 'rnn_layers' not found in: ['seed', '__set_seed', 'data_folder', 'output_folder', 'save_folder', 'train_log', 'rir_folder', 'train_annotation', 'valid_annotation', 'test_annotation', 'split_ratio', 'skip_prep', 'train_logger', 'error_stats', 'ckpt_interval_minutes', 'n_mels', 'sample_rate', 'number_of_epochs', 'batch_size', 'lr_start', 'lr_final', 'n_classes', 'emb_dim', 'dataloader_options', 'env_corrupt', 'augmentation', 'compute_features', 'mean_var_norm', 'embedding_model', 'classifier', 'epoch_counter', 'modules', 'opt_class', 'lr_annealing', 'checkpointer']\"\n","Traceback (most recent call last):\n","  File \"/content/speechbrain/templates/speaker_id/train.py\", line 290, in <module>\n","    hparams = load_hyperpyyaml(fin, overrides)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 157, in load_hyperpyyaml\n","    yaml_stream = resolve_references(yaml_stream, overrides, overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 316, in resolve_references\n","    recursive_update(preview, overrides, must_match=overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 778, in recursive_update\n","    raise KeyError(f\"Override '{k}' not found in: {[key for key in d.keys()]}\")\n","KeyError: \"Override 'rnn_layers' not found in: ['seed', '__set_seed', 'data_folder', 'output_folder', 'save_folder', 'train_log', 'rir_folder', 'train_annotation', 'valid_annotation', 'test_annotation', 'split_ratio', 'skip_prep', 'train_logger', 'error_stats', 'ckpt_interval_minutes', 'n_mels', 'sample_rate', 'number_of_epochs', 'batch_size', 'lr_start', 'lr_final', 'n_classes', 'emb_dim', 'dataloader_options', 'env_corrupt', 'augmentation', 'compute_features', 'mean_var_norm', 'embedding_model', 'classifier', 'epoch_counter', 'modules', 'opt_class', 'lr_annealing', 'checkpointer']\"\n","Traceback (most recent call last):\n","  File \"/content/speechbrain/templates/speaker_id/train.py\", line 290, in <module>\n","    hparams = load_hyperpyyaml(fin, overrides)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 157, in load_hyperpyyaml\n","    yaml_stream = resolve_references(yaml_stream, overrides, overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 316, in resolve_references\n","    recursive_update(preview, overrides, must_match=overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 778, in recursive_update\n","    raise KeyError(f\"Override '{k}' not found in: {[key for key in d.keys()]}\")\n","KeyError: \"Override 'rnn_layers' not found in: ['seed', '__set_seed', 'data_folder', 'output_folder', 'save_folder', 'train_log', 'rir_folder', 'train_annotation', 'valid_annotation', 'test_annotation', 'split_ratio', 'skip_prep', 'train_logger', 'error_stats', 'ckpt_interval_minutes', 'n_mels', 'sample_rate', 'number_of_epochs', 'batch_size', 'lr_start', 'lr_final', 'n_classes', 'emb_dim', 'dataloader_options', 'env_corrupt', 'augmentation', 'compute_features', 'mean_var_norm', 'embedding_model', 'classifier', 'epoch_counter', 'modules', 'opt_class', 'lr_annealing', 'checkpointer']\"\n","Traceback (most recent call last):\n","  File \"/content/speechbrain/templates/speaker_id/train.py\", line 290, in <module>\n","    hparams = load_hyperpyyaml(fin, overrides)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 157, in load_hyperpyyaml\n","    yaml_stream = resolve_references(yaml_stream, overrides, overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 316, in resolve_references\n","    recursive_update(preview, overrides, must_match=overrides_must_match)\n","  File \"/usr/local/lib/python3.10/dist-packages/hyperpyyaml/core.py\", line 778, in recursive_update\n","    raise KeyError(f\"Override '{k}' not found in: {[key for key in d.keys()]}\")\n","KeyError: \"Override 'rnn_layers' not found in: ['seed', '__set_seed', 'data_folder', 'output_folder', 'save_folder', 'train_log', 'rir_folder', 'train_annotation', 'valid_annotation', 'test_annotation', 'split_ratio', 'skip_prep', 'train_logger', 'error_stats', 'ckpt_interval_minutes', 'n_mels', 'sample_rate', 'number_of_epochs', 'batch_size', 'lr_start', 'lr_final', 'n_classes', 'emb_dim', 'dataloader_options', 'env_corrupt', 'augmentation', 'compute_features', 'mean_var_norm', 'embedding_model', 'classifier', 'epoch_counter', 'modules', 'opt_class', 'lr_annealing', 'checkpointer']\"\n"]}],"source":["##Com o comando abaixo, podemos executar vários treinamentos usando o mesmo arquivo de parâmetros, onde se alteram variaveis unicas para a execução, sendo diferenciados pelo seed que cria uma pasta diferente para cada um, definido também nos parametros\n","%cd /content/speechbrain/templates/speaker_id\n","\n","!python train.py train.yaml --number_of_epochs=15 --n_mels=10 --seed=123 --rnn_layers=3 --learning_rate=0.001\n","\n","!python train.py train.yaml --number_of_epochs=15 --n_mels=20 --seed=456 --rnn_layers=2 --learning_rate=0.01\n","\n","!python train.py train.yaml --number_of_epochs=20 --n_mels=15 --seed=789 --rnn_layers=4 --learning_rate=0.0005\n","\n","!python train.py train.yaml --number_of_epochs=20 --n_mels=12 --seed=321 --rnn_layers=2 --rnn_neurons=512 --learning_rate=0.0015\n","\n","!python train.py train.yaml --number_of_epochs=12 --n_mels=18 --seed=555 --rnn_layers=3 --rnn_neurons=256 --learning_rate=0.002\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OExXDp9RNjCR","outputId":"d984dcfc-110a-4b78-b6d1-10800b278e9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[WinError 3] The system cannot find the path specified: '/content/speechbrain/templates/speaker_id'\n","C:\\Users\\amori\\Downloads\n"]},{"name":"stderr","output_type":"stream","text":["python: can't open file 'C:\\\\Users\\\\amori\\\\Downloads\\\\train.py': [Errno 2] No such file or directory\n","python: can't open file 'C:\\\\Users\\\\amori\\\\Downloads\\\\train.py': [Errno 2] No such file or directory\n","python: can't open file 'C:\\\\Users\\\\amori\\\\Downloads\\\\train.py': [Errno 2] No such file or directory\n","python: can't open file 'C:\\\\Users\\\\amori\\\\Downloads\\\\train.py': [Errno 2] No such file or directory\n","python: can't open file 'C:\\\\Users\\\\amori\\\\Downloads\\\\train.py': [Errno 2] No such file or directory\n"]}],"source":["#Neste passo, foram criados 5 tipos de treinamento alterando os hiperparametros, mas o passo anterior torna ele desnecessário\n","%cd /content/speechbrain/templates/speaker_id\n","!python train.py train1.yaml\n","!python train.py train2.yaml\n","!python train.py train3.yaml\n","!python train.py train4.yaml\n","!python train.py train5.yaml"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"G49Hap0CGV0s","outputId":"cf14259d-8de4-4231-85a6-b98b9da97eed","executionInfo":{"status":"error","timestamp":1695556119002,"user_tz":180,"elapsed":241,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[{"output_type":"error","ename":"HFValidationError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-19f86c5fff73>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Carregar o modelo treinado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaminho_modelo_treinado\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Carregar um sinal de áudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/speechbrain/speechbrain/pretrained/interfaces.py\u001b[0m in \u001b[0;36mfrom_hparams\u001b[0;34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, revision, download_only, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mclsname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0msavedir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"./pretrained_models/{clsname}-{hashlib.md5(source.encode('UTF-8', errors='replace')).hexdigest()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         hparams_local_path = fetch(\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/speechbrain/speechbrain/pretrained/fetching.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(filename, source, savedir, overwrite, save_filename, use_auth_token, revision, cache_dir, silent_local_fetch)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             fetched_file = huggingface_hub.hf_hub_download(\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         ):\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"token\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;34mf\" '{repo_id}'. Use `repo_type` argument if needed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/speechbrain/templates/speaker_id/results/speaker_id/1988'. Use `repo_type` argument if needed."]}],"source":["import torchaudio\n","from speechbrain.pretrained import EncoderClassifier\n","import os\n","\n","# Caminho para o modelo treinado\n","caminho_modelo_treinado = \"/content/speechbrain/templates/speaker_id/results/speaker_id/1988\"\n","\n","# Carregar o modelo treinado\n","classifier = EncoderClassifier.from_hparams(source=caminho_modelo_treinado)\n","\n","# Carregar um sinal de áudio\n","signal, fs = torchaudio.load('/content/speechbrain/tests/samples/single-mic/example1.wav')\n","\n","# Calcular embeddings dos locutores\n","embeddings = classifier.encode_batch(signal)\n","\n","# Realizar classificação\n","output_probs, score, index, text_lab = classifier.classify_batch(signal)\n","\n","# Posterior log probabilities\n","print(output_probs)\n","\n","# Score (i.e, max log posteriors)\n","print(score)\n","\n","# Index of the predicted speaker\n","print(index)\n","\n","# Text label of the predicted speaker\n","print(text_lab)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"id":"CMQ74s-HCBCR","outputId":"27d3ff3c-de84-4007-89dd-250e04b769e4"},"outputs":[{"ename":"KeyError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-5bb7022a9f18>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderDecoderASR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0masr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderDecoderASR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/speechbrain/templates/speaker_id/results/speaker_id/1988/save/CKPT+2023-09-23+14-18-21+00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/speechbrain/templates/speaker_id/results/speaker_id/1988/save/CKPT+2023-09-23+14-18-21+00/CKPT.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavedir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/speechbrain/templates/speaker_id/results/speaker_id/1988/save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'your_file.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0masr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/speechbrain/speechbrain/pretrained/interfaces.py\u001b[0m in \u001b[0;36mfrom_hparams\u001b[0;34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, revision, download_only, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Pretraining:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mpretrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pretrainer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0mpretrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_collect_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# For distributed setups, have this here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'pretrainer'"]}],"source":["from speechbrain.pretrained import EncoderDecoderASR\n","\n","asr_model = EncoderDecoderASR.from_hparams(source=\"/content/speechbrain/templates/speaker_id/results/speaker_id/1988/save/CKPT+2023-09-23+14-18-21+00\", hparams_file='/content/speechbrain/templates/speaker_id/results/speaker_id/1988/save/CKPT+2023-09-23+14-18-21+00/CKPT.yaml', savedir=\"/content/speechbrain/templates/speaker_id/results/speaker_id/1988/save\")\n","audio_file = '/content/speechbrain/tests/samples/single-mic/example1.wav'\n","asr_model.transcribe_file(audio_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krz188MWIS2S","outputId":"b8dacd2b-0bad-448b-c288-098e5f3d3720"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting /content/speechbrain/templates/speaker_id/results/speaker_id/1986/save/CKPT+2023-09-23+12-23-22+00/CKPT.yaml\n"]}],"source":["%%writefile /content/speechbrain/templates/speaker_id/results/speaker_id/1986/save/CKPT+2023-09-23+12-23-22+00/CKPT.yaml\n","\n","# #################################\n","# Basic inference parameters for speaker-id. We have first a network that\n","# computes some embeddings. On the top of that, we employ a classifier.\n","#\n","# Author:\n","#  * Mirco Ravanelli 2021\n","# #################################\n","\n","# pretrain folders:\n","pretrained_path: /content/best_model/\n","\n","\n","# Model parameters\n","n_mels: 23\n","sample_rate: 16000\n","n_classes: 28 # In this case, we have 28 speakers\n","emb_dim: 512 # dimensionality of the embeddings\n","\n","# Feature extraction\n","compute_features: !new:speechbrain.lobes.features.Fbank\n","    n_mels: !ref <n_mels>\n","\n","# Mean and std normalization of the input features\n","mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n","    norm_type: sentence\n","    std_norm: False\n","\n","# To design a custom model, either just edit the simple CustomModel\n","# class that's listed here, or replace this `!new` call with a line\n","# pointing to a different file you've defined.\n","embedding_model: !new:custom_model.Xvector\n","    in_channels: !ref <n_mels>\n","    activation: !name:torch.nn.LeakyReLU\n","    tdnn_blocks: 5\n","    tdnn_channels: [512, 512, 512, 512, 1500]\n","    tdnn_kernel_sizes: [5, 3, 3, 1, 1]\n","    tdnn_dilations: [1, 2, 3, 1, 1]\n","    lin_neurons: !ref <emb_dim>\n","\n","classifier: !new:custom_model.Classifier\n","    input_shape: [null, null, !ref <emb_dim>]\n","    activation: !name:torch.nn.LeakyReLU\n","    lin_blocks: 1\n","    lin_neurons: !ref <emb_dim>\n","    out_neurons: !ref <n_classes>\n","\n","label_encoder: !new:speechbrain.dataio.encoder.CategoricalEncoder\n","\n","# Objects in \"modules\" dict will have their parameters moved to the correct\n","# device, as well as having train()/eval() called on them by the Brain class.\n","modules:\n","    compute_features: !ref <compute_features>\n","    embedding_model: !ref <embedding_model>\n","    classifier: !ref <classifier>\n","    mean_var_norm: !ref <mean_var_norm>\n","\n","pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n","    loadables:\n","        embedding_model: !ref <embedding_model>\n","        classifier: !ref <classifier>\n","        label_encoder: !ref <label_encoder>\n","    paths:\n","        embedding_model: !ref <pretrained_path>/embedding_model.ckpt\n","        classifier: !ref <pretrained_path>/classifier.ckpt\n","        label_encoder: !ref <pretrained_path>/label_encoder.txt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZDxn9muGKJV6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"3PteI6LHNqb9","outputId":"58d58a0c-5caf-4713-825f-6620417e09f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["./data/rirs_noises.zip exists. Skipping download\n"]},{"ename":"KeyError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-003e837fcaff>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpeakerRecognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mverification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeakerRecognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaminho_modelo_treinado\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/speechbrain/tests/samples/single-mic/example1.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/speechbrain/tests/samples/single-mic/example2.flac'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/speechbrain/speechbrain/pretrained/interfaces.py\u001b[0m in \u001b[0;36mfrom_hparams\u001b[0;34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, revision, download_only, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Pretraining:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mpretrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pretrainer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0mpretrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_collect_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# For distributed setups, have this here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'pretrainer'"]}],"source":["from speechbrain.pretrained import SpeakerRecognition\n","verification = SpeakerRecognition.from_hparams(source=caminho_modelo_treinado)\n","\n","file1 = '/content/speechbrain/tests/samples/single-mic/example1.wav'\n","file2 = '/content/speechbrain/tests/samples/single-mic/example2.flac'\n","\n","score, prediction = verification.verify_files(file1, file2)\n","\n","print(score)\n","print(prediction) # True = same speaker, False=Different speakers\n"]},{"cell_type":"markdown","metadata":{"id":"W4pPJ0k3lJZj"},"source":["\n","\n","## **Conclusão**\n","\n","Nesse notebook, foi feito um modelo de comparação entre audios para definição estatística se um áudio tem a mesma voz de outro áudio, por meio do treinamento de uma rede neural que extrai features de arquivos de voz. Para a comparação das redes treinadas, não foi possível executá-las por não conseguir alterar do best_model para as variações."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}