{"cells":[{"cell_type":"markdown","metadata":{"id":"f79d99ef"},"source":["# Train your first 🐸 TTS model 💫\n","\n","### 👋 Hello and welcome to Coqui (🐸) TTS\n","\n","The goal of this notebook is to show you a **typical workflow** for **training** and **testing** a TTS model with 🐸.\n","\n","Let's train a very small model on a very small amount of data so we can iterate quickly.\n","\n","In this notebook, we will:\n","\n","1. Download data and format it for 🐸 TTS.\n","2. Configure the training and testing runs.\n","3. Train a new model.\n","4. Test the model and display its performance.\n","\n","So, let's jump right in!\n"],"id":"f79d99ef"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":91860,"status":"ok","timestamp":1694694749488,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"fa2aec78","outputId":"f03fba80-9a21-43bb-ec1c-947bea3de540"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-23.2.1\n","Collecting TTS\n","  Obtaining dependency information for TTS from https://files.pythonhosted.org/packages/e9/cc/30baf6fc51f05abd5cea7c27b9d13c1a0fe29be6bab204ebaf906efd8dbc/TTS-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata\n","  Downloading TTS-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (21 kB)\n","Collecting cython==0.29.30 (from TTS)\n","  Downloading Cython-0.29.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.2)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.1+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.2+cu118)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n","Collecting librosa==0.10.0.* (from TTS)\n","  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting inflect==5.6.0 (from TTS)\n","  Downloading inflect-5.6.0-py3-none-any.whl (33 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from TTS) (4.66.1)\n","Collecting anyascii (from TTS)\n","  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.1)\n","Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TTS) (23.1)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n","Collecting pysbd (from TTS)\n","  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting umap-learn==0.5.1 (from TTS)\n","  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n","Collecting trainer (from TTS)\n","  Obtaining dependency information for trainer from https://files.pythonhosted.org/packages/14/93/32ab47a46633c889b5980a6525e4dd74e2bc71864d8498bd9c6e1233b8b0/trainer-0.0.31-py3-none-any.whl.metadata\n","  Downloading trainer-0.0.31-py3-none-any.whl.metadata (8.1 kB)\n","Collecting coqpit>=0.0.16 (from TTS)\n","  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n","Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n","Collecting pypinyin (from TTS)\n","  Obtaining dependency information for pypinyin from https://files.pythonhosted.org/packages/00/fc/3e82bf38739a7b2c4f699245ce6c84ff254723c678c2cdc5d2ecbddf9afb/pypinyin-0.49.0-py2.py3-none-any.whl.metadata\n","  Downloading pypinyin-0.49.0-py2.py3-none-any.whl.metadata (12 kB)\n","Collecting gruut[de,es,fr]==2.2.3 (from TTS)\n","  Downloading gruut-2.2.3.tar.gz (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jamo (from TTS)\n","  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n","Collecting g2pkk>=0.1.1 (from TTS)\n","  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n","Collecting bangla==0.0.2 (from TTS)\n","  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n","Collecting bnnumerizer (from TTS)\n","  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting bnunicodenormalizer==0.1.1 (from TTS)\n","  Downloading bnunicodenormalizer-0.1.1.tar.gz (38 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting k-diffusion (from TTS)\n","  Obtaining dependency information for k-diffusion from https://files.pythonhosted.org/packages/57/b2/2175ab0a77e1d17df21f925ab436cd0d330dff2c689db770f330353f83d5/k_diffusion-0.0.16-py3-none-any.whl.metadata\n","  Downloading k_diffusion-0.0.16-py3-none-any.whl.metadata (3.7 kB)\n","Collecting einops (from TTS)\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers (from TTS)\n","  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/13/30/54b59e73400df3de506ad8630284e9fd63f4b94f735423d55fc342181037/transformers-4.33.1-py3-none-any.whl.metadata\n","  Downloading transformers-4.33.1-py3-none-any.whl.metadata (119 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting encodec (from TTS)\n","  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting unidecode (from TTS)\n","  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy==1.22.0 (from TTS)\n","  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numba==0.57.0 (from TTS)\n","  Downloading numba-0.57.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.12.1)\n","Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n","Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting num2words<1.0.0,>=0.5.10 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (3.0.0)\n","INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n","Collecting librosa==0.10.0.* (from TTS)\n","  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m526.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.3.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.4.2)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.7.0)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.3.6)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.5.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.3)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.0.5)\n","Collecting llvmlite<0.41,>=0.40.0dev0 (from numba==0.57.0->TTS)\n","  Obtaining dependency information for llvmlite<0.41,>=0.40.0dev0 from https://files.pythonhosted.org/packages/14/73/424ef49a4bb7bbc9c16f3fc66926cb3018699c69146cd130642c76ff2d97/llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n","Collecting pynndescent>=0.5 (from umap-learn==0.5.1->TTS)\n","  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->TTS) (1.15.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (16.0.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.3.1)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.3.7)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (8.1.7)\n","Collecting accelerate (from k-diffusion->TTS)\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/4d/a7/05c67003d659a0035f2b3a8cf389c1d9645865aee84a73ce99ddab16682f/accelerate-0.22.0-py3-none-any.whl.metadata\n","  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\n","Collecting clean-fid (from k-diffusion->TTS)\n","  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n","Collecting clip-anytorch (from k-diffusion->TTS)\n","  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonmerge (from k-diffusion->TTS)\n","  Obtaining dependency information for jsonmerge from https://files.pythonhosted.org/packages/71/c2/1032d0dbc2152c45f3d1e582a72e68f41898de9665202392d9400dfa329d/jsonmerge-1.9.2-py3-none-any.whl.metadata\n","  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n","Collecting kornia (from k-diffusion->TTS)\n","  Obtaining dependency information for kornia from https://files.pythonhosted.org/packages/55/da/72cb83aa364ebb4d0109965e20c5d33d7063ccab15332c3fd0acfd5609c9/kornia-0.7.0-py2.py3-none-any.whl.metadata\n","  Downloading kornia-0.7.0-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (9.4.0)\n","Collecting resize-right (from k-diffusion->TTS)\n","  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.19.3)\n","Collecting torchdiffeq (from k-diffusion->TTS)\n","  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n","Collecting torchsde (from k-diffusion->TTS)\n","  Downloading torchsde-0.2.5-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.15.2+cu118)\n","Collecting wandb (from k-diffusion->TTS)\n","  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/fe/10/18b03623c460fd433525d9b4739af58c5e69f5974328dcdd037cfbc855d7/wandb-0.15.10-py3-none-any.whl.metadata\n","  Downloading wandb-0.15.10-py3-none-any.whl.metadata (9.6 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (2.8.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->TTS) (2023.6.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TTS) (2023.3.post1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (5.9.5)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (2.13.0)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers->TTS)\n","  Obtaining dependency information for huggingface-hub<1.0,>=0.15.1 from https://files.pythonhosted.org/packages/50/9d/5eac2733606df7d164b951b14cd76b056e530af96c881aaec89383bdbe45/huggingface_hub-0.17.1-py3-none-any.whl.metadata\n","  Downloading huggingface_hub-0.17.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->TTS) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->TTS)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->TTS)\n","  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/6c/f0/c17bbdb1e5f9dab29d44cade445135789f75f8f08ea2728d04493ea8412b/safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->TTS) (2.21)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->TTS) (2.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n","Collecting docopt>=0.6.2 (from num2words<1.0.0,>=0.5.10->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.10.0.*->TTS) (3.10.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (2023.7.22)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.0.*->TTS) (3.2.0)\n","Collecting ftfy (from clip-anytorch->k-diffusion->TTS)\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->TTS) (4.19.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2.31.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2023.8.30)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (1.4.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->TTS) (1.3.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.57.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.4.4)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.7.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.41.2)\n","Collecting boltons>=20.2.1 (from torchsde->k-diffusion->TTS)\n","  Downloading boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trampoline>=0.1.2 (from torchsde->k-diffusion->TTS)\n","  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->k-diffusion->TTS)\n","  Obtaining dependency information for GitPython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/f9/94/1877b88fa3a0a30bedb43757a14f548c3b2719c8d83c16012f89564c0f3b/GitPython-3.1.36-py3-none-any.whl.metadata\n","  Downloading GitPython-3.1.36-py3-none-any.whl.metadata (12 kB)\n","Collecting sentry-sdk>=1.0.0 (from wandb->k-diffusion->TTS)\n","  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/62/3a/765a7699a26884dcbf8b071dbe2a2486cc1cafcfb5f5d2e64ffe745dd0c6/sentry_sdk-1.31.0-py2.py3-none-any.whl.metadata\n","  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl.metadata (9.8 kB)\n","Collecting docker-pycreds>=0.4.0 (from wandb->k-diffusion->TTS)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb->k-diffusion->TTS)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb->k-diffusion->TTS)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (1.4.4)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS) (1.3.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.10.2)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch->k-diffusion->TTS) (0.2.6)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS) (3.2.2)\n","Downloading TTS-0.17.1-cp310-cp310-manylinux1_x86_64.whl (867 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.1/867.1 kB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading k_diffusion-0.0.16-py3-none-any.whl (25 kB)\n","Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trainer-0.0.31-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n","Downloading kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.7/705.7 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wandb-0.15.10-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: bnunicodenormalizer, umap-learn, bnnumerizer, encodec, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, pynndescent, gruut, docopt, pathtools\n","  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.1-py3-none-any.whl size=21895 sha256=64351123e9e3cbd280c9813e97d8a4b8d740ee1f30330f167b3a1e555a91a56c\n","  Stored in directory: /root/.cache/pip/wheels/b4/f6/01/9e68ecec7c7ea85fc9431cfac42eba1c5a5f6debe5070de5c7\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76543 sha256=1df97db4f8755063b64fd5c1036da31c6aeb36294e9c0117a948967166085123\n","  Stored in directory: /root/.cache/pip/wheels/69/21/8e/802cb9c4c606a67139f538cb17bf3bf1b98b739a7900469953\n","  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=2ef6183bf8a9f52e51f2afb478ce4328857a502ef0f28f2a305eb23c8c990944\n","  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n","  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=1906d16a92ddc741dc1bd05f18614f144963fbd80e8e61a61c24cd19812dcdf2\n","  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n","  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104871 sha256=6b3aa96e9b04552b4b71f822c58329c97f288ffe504d9fe3a5b6c25740272673\n","  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n","  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498181 sha256=28cf251c5e8f4f15c19197e5f6f916ecdcf6a9132dcf46457cf555c34960224e\n","  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n","  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297179 sha256=db1bf28c64614d63628092084908562973c8425a54f16c35c846abd974ccc195\n","  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n","  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173797 sha256=90467497902d025f20a7a5ac6b3643ad2feba9f88e202e51974bab66d41267c0\n","  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n","  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=2c701f005972a1f7e1e75044136fc6f8434e8085c327022ee762358e15a961de\n","  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n","  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=c658840118d4e94624712a85261514e85a0eb69bbbd6ff0af3697c8685b00e2d\n","  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n","  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75793 sha256=a9baca648793ac98a80c303e42de53ef57cff0b6445d2bcb0a67ad657089f87c\n","  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=305b15387354a1b20915333b2ae8a89c2e8d5bbc66155d68e495dde563a1726a\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=c1782cf18573ad3758bf734049e3a7a23ab075060f74c997a9eb44817d2d67d5\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built bnunicodenormalizer umap-learn bnnumerizer encodec gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr pynndescent gruut docopt pathtools\n","\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: trampoline, tokenizers, safetensors, resize-right, python-crfsuite, pathtools, jamo, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, boltons, bnunicodenormalizer, bnnumerizer, bangla, unidecode, smmap, setproctitle, sentry-sdk, pysbd, pypinyin, numpy, num2words, networkx, llvmlite, jsonlines, inflect, gruut-ipa, ftfy, einops, docker-pycreds, cython, coqpit, anyascii, numba, huggingface-hub, gitdb, g2pkk, dateparser, transformers, gruut, GitPython, wandb, pynndescent, librosa, jsonmerge, umap-learn, torchsde, torchdiffeq, kornia, clip-anytorch, clean-fid, accelerate, trainer, k-diffusion, encodec, TTS\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.1\n","    Uninstalling networkx-3.1:\n","      Successfully uninstalled networkx-3.1\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.39.1\n","    Uninstalling llvmlite-0.39.1:\n","      Successfully uninstalled llvmlite-0.39.1\n","  Attempting uninstall: inflect\n","    Found existing installation: inflect 7.0.0\n","    Uninstalling inflect-7.0.0:\n","      Successfully uninstalled inflect-7.0.0\n","  Attempting uninstall: cython\n","    Found existing installation: Cython 3.0.2\n","    Uninstalling Cython-3.0.2:\n","      Successfully uninstalled Cython-3.0.2\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.56.4\n","    Uninstalling numba-0.56.4:\n","      Successfully uninstalled numba-0.56.4\n","  Attempting uninstall: librosa\n","    Found existing installation: librosa 0.10.1\n","    Uninstalling librosa-0.10.1:\n","      Successfully uninstalled librosa-0.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","plotnine 0.12.3 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.36 TTS-0.17.1 accelerate-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.1 boltons-23.0.0 clean-fid-0.1.35 clip-anytorch-2.5.2 coqpit-0.0.17 cython-0.29.30 dateparser-1.1.8 docker-pycreds-0.4.0 docopt-0.6.2 einops-0.6.1 encodec-0.1.1 ftfy-6.1.1 g2pkk-0.1.2 gitdb-4.0.10 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 huggingface-hub-0.17.1 inflect-5.6.0 jamo-0.4.1 jsonlines-1.2.0 jsonmerge-1.9.2 k-diffusion-0.0.16 kornia-0.7.0 librosa-0.10.0 llvmlite-0.40.1 networkx-2.8.8 num2words-0.5.12 numba-0.57.0 numpy-1.22.0 pathtools-0.1.2 pynndescent-0.5.10 pypinyin-0.49.0 pysbd-0.3.4 python-crfsuite-0.9.9 resize-right-0.0.2 safetensors-0.3.3 sentry-sdk-1.31.0 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 torchdiffeq-0.2.3 torchsde-0.2.5 trainer-0.0.31 trampoline-0.1.2 transformers-4.33.1 umap-learn-0.5.1 unidecode-1.3.6 wandb-0.15.10\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}],"source":["## Install Coqui TTS\n","! pip install -U pip\n","! pip install TTS"],"id":"fa2aec78"},{"cell_type":"markdown","metadata":{"id":"be5fe49c"},"source":["## ✅ Data Preparation\n","\n","### **First things first**: we need some data.\n","\n","We're training a Text-to-Speech model, so we need some _text_ and we need some _speech_. Specificially, we want _transcribed speech_. The speech must be divided into audio clips and each clip needs transcription. More details about data requirements such as recording characteristics, background noise and vocabulary coverage can be found in the [🐸TTS documentation](https://tts.readthedocs.io/en/latest/formatting_your_dataset.html).\n","\n","If you have a single audio file and you need to **split** it into clips. It is also important to use a lossless audio file format to prevent compression artifacts. We recommend using **wav** file format.\n","\n","The data format we will be adopting for this tutorial is taken from the widely-used  **LJSpeech** dataset, where **waves** are collected under a folder:\n","\n","<span style=\"color:purple;font-size:15px\">\n","/wavs<br />\n"," &emsp;| - audio1.wav<br />\n"," &emsp;| - audio2.wav<br />\n"," &emsp;| - audio3.wav<br />\n","  ...<br />\n","</span>\n","\n","and a **metadata.csv** file will have the audio file name in parallel to the transcript, delimited by `|`:\n","\n","<span style=\"color:purple;font-size:15px\">\n","# metadata.csv <br />\n","audio1|This is my sentence. <br />\n","audio2|This is maybe my sentence. <br />\n","audio3|This is certainly my sentence. <br />\n","audio4|Let this be your sentence. <br />\n","...\n","</span>\n","\n","In the end, we should have the following **folder structure**:\n","\n","<span style=\"color:purple;font-size:15px\">\n","/MyTTSDataset <br />\n","&emsp;| <br />\n","&emsp;| -> metadata.csv<br />\n","&emsp;| -> /wavs<br />\n","&emsp;&emsp;| -> audio1.wav<br />\n","&emsp;&emsp;| -> audio2.wav<br />\n","&emsp;&emsp;| ...<br />\n","</span>"],"id":"be5fe49c"},{"cell_type":"markdown","metadata":{"id":"69501a10-3b53-4e75-ae66-90221d6f2271"},"source":["🐸TTS already provides tooling for the _LJSpeech_. if you use the same format, you can start training your models right away. <br />\n","\n","After you collect and format your dataset, you need to check two things. Whether you need a **_formatter_** and a **_text_cleaner_**. <br /> The **_formatter_** loads the text file (created above) as a list and the **_text_cleaner_** performs a sequence of text normalization operations that converts the raw text into the spoken representation (e.g. converting numbers to text, acronyms, and symbols to the spoken format).\n","\n","If you use a different dataset format then the LJSpeech or the other public datasets that 🐸TTS supports, then you need to write your own **_formatter_** and  **_text_cleaner_**."],"id":"69501a10-3b53-4e75-ae66-90221d6f2271"},{"cell_type":"markdown","metadata":{"id":"e7f226c8-4e55-48fa-937b-8415d539b17c"},"source":["## ⏳️ Loading your dataset\n","Load one of the dataset supported by 🐸TTS.\n","\n","We will start by defining dataset config and setting LJSpeech as our target dataset and define its path.\n"],"id":"e7f226c8-4e55-48fa-937b-8415d539b17c"},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5603,"status":"ok","timestamp":1694694768483,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"b3cb0191-b8fc-4158-bd26-8423c2a8ba66"},"outputs":[],"source":["import os\n","\n","# BaseDatasetConfig: defines name, formatter and path of the dataset.\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig\n","\n","output_path = \"tts_train_dir\"\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path)\n"],"id":"b3cb0191-b8fc-4158-bd26-8423c2a8ba66"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae6b7019-3685-4b48-8917-c152e288d7e3","executionInfo":{"status":"ok","timestamp":1694695140088,"user_tz":180,"elapsed":328783,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}},"outputId":"e0306206-4703-4beb-f2d0-2f9f2bd972a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-09-14 12:33:31--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n","Resolving data.keithito.com (data.keithito.com)... 24.199.73.137\n","Connecting to data.keithito.com (data.keithito.com)|24.199.73.137|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2748572632 (2.6G) [text/plain]\n","Saving to: ‘tts_train_dir/LJSpeech-1.1.tar.bz2’\n","\n","tts_train_dir/LJSpe 100%[===================>]   2.56G  56.0MB/s    in 49s     \n","\n","2023-09-14 12:34:20 (53.7 MB/s) - ‘tts_train_dir/LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n","\n"]}],"source":["# Download and extract LJSpeech dataset.\n","\n","!wget -O $output_path/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n","!tar -xf $output_path/LJSpeech-1.1.tar.bz2 -C $output_path"],"id":"ae6b7019-3685-4b48-8917-c152e288d7e3"},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1694694775062,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"76cd3ab5-6387-45f1-b488-24734cc1beb5"},"outputs":[],"source":["dataset_config = BaseDatasetConfig(\n","    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"LJSpeech-1.1/\")\n",")"],"id":"76cd3ab5-6387-45f1-b488-24734cc1beb5"},{"cell_type":"markdown","metadata":{"id":"ae82fd75"},"source":["## ✅ Train a new model\n","\n","Let's kick off a training run 🚀🚀🚀.\n","\n","Deciding on the model architecture you'd want to use is based on your needs and available resources. Each model architecture has it's pros and cons that define the run-time efficiency and the voice quality.\n","We have many recipes under `TTS/recipes/` that provide a good starting point. For this tutorial, we will be using `GlowTTS`."],"id":"ae82fd75"},{"cell_type":"markdown","metadata":{"id":"f5876e46-2aee-4bcf-b6b3-9e3c535c553f"},"source":["We will begin by initializing the model training configuration."],"id":"f5876e46-2aee-4bcf-b6b3-9e3c535c553f"},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":224,"status":"ok","timestamp":1694694780689,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"5483ca28-39d6-49f8-a18e-4fb53c50ad84"},"outputs":[],"source":["# GlowTTSConfig: all model related values for training, validating and testing.\n","from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n","config = GlowTTSConfig(\n","    batch_size=32,\n","    eval_batch_size=16,\n","    num_loader_workers=4,\n","    num_eval_loader_workers=4,\n","    run_eval=True,\n","    test_delay_epochs=-1,\n","    epochs=1,\n","    text_cleaner=\"phoneme_cleaners\",\n","    use_phonemes=True,\n","    phoneme_language=\"en-us\",\n","    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n","    print_step=25,\n","    print_eval=False,\n","    mixed_precision=True,\n","    output_path=output_path,\n","    datasets=[dataset_config],\n","    save_step=1000,\n",")"],"id":"5483ca28-39d6-49f8-a18e-4fb53c50ad84"},{"cell_type":"markdown","metadata":{"id":"b93ed377-80b7-447b-bd92-106bffa777ee"},"source":["Next we will initialize the audio processor which is used for feature extraction and audio I/O."],"id":"b93ed377-80b7-447b-bd92-106bffa777ee"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8988,"status":"ok","timestamp":1694694792129,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"b1b12f61-f851-4565-84dd-7640947e04ab","outputId":"b837e930-2108-4f47-bdd3-c9741169299b"},"outputs":[{"output_type":"stream","name":"stdout","text":[" > Setting up Audio Processor...\n"," | > sample_rate:22050\n"," | > resample:False\n"," | > num_mels:80\n"," | > log_func:np.log10\n"," | > min_level_db:-100\n"," | > frame_shift_ms:None\n"," | > frame_length_ms:None\n"," | > ref_level_db:20\n"," | > fft_size:1024\n"," | > power:1.5\n"," | > preemphasis:0.0\n"," | > griffin_lim_iters:60\n"," | > signal_norm:True\n"," | > symmetric_norm:True\n"," | > mel_fmin:0\n"," | > mel_fmax:None\n"," | > pitch_fmin:1.0\n"," | > pitch_fmax:640.0\n"," | > spec_gain:20.0\n"," | > stft_pad_mode:reflect\n"," | > max_norm:4.0\n"," | > clip_norm:True\n"," | > do_trim_silence:True\n"," | > trim_db:45\n"," | > do_sound_norm:False\n"," | > do_amp_to_db_linear:True\n"," | > do_amp_to_db_mel:True\n"," | > do_rms_norm:False\n"," | > db_level:None\n"," | > stats_path:None\n"," | > base:10\n"," | > hop_length:256\n"," | > win_length:1024\n"]}],"source":["from TTS.utils.audio import AudioProcessor\n","ap = AudioProcessor.init_from_config(config)\n","# Modify sample rate if for a custom audio dataset:\n","# ap.sample_rate = 22050\n"],"id":"b1b12f61-f851-4565-84dd-7640947e04ab"},{"cell_type":"markdown","metadata":{"id":"1d461683-b05e-403f-815f-8007bda08c38"},"source":["Next we will initialize the tokenizer which is used to convert text to sequences of token IDs.  If characters are not defined in the config, default characters are passed to the config."],"id":"1d461683-b05e-403f-815f-8007bda08c38"},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1875,"status":"ok","timestamp":1694694797299,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"014879b7-f18d-44c0-b24a-e10f8002113a"},"outputs":[],"source":["from TTS.tts.utils.text.tokenizer import TTSTokenizer\n","tokenizer, config = TTSTokenizer.init_from_config(config)"],"id":"014879b7-f18d-44c0-b24a-e10f8002113a"},{"cell_type":"markdown","metadata":{"id":"df3016e1-9e99-4c4f-94e3-fa89231fd978"},"source":["Next we will load data samples. Each sample is a list of ```[text, audio_file_path, speaker_name]```. You can define your custom sample loader returning the list of samples."],"id":"df3016e1-9e99-4c4f-94e3-fa89231fd978"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":662,"status":"ok","timestamp":1694695167057,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"cadd6ada-c8eb-4f79-b8fe-6d72850af5a7","outputId":"38fa249a-3e11-49c9-8b5d-5c806e619bb3"},"outputs":[{"output_type":"stream","name":"stdout","text":[" | > Found 13100 files in /content/tts_train_dir/LJSpeech-1.1\n"]}],"source":["from TTS.tts.datasets import load_tts_samples\n","train_samples, eval_samples = load_tts_samples(\n","    dataset_config,\n","    eval_split=True,\n","    eval_split_max_size=config.eval_split_max_size,\n","    eval_split_size=config.eval_split_size,\n",")"],"id":"cadd6ada-c8eb-4f79-b8fe-6d72850af5a7"},{"cell_type":"markdown","metadata":{"id":"db8b451e-1fe1-4aa3-b69e-ab22b925bd19"},"source":["Now we're ready to initialize the model.\n","\n","Models take a config object and a speaker manager as input. Config defines the details of the model like the number of layers, the size of the embedding, etc. Speaker manager is used by multi-speaker models."],"id":"db8b451e-1fe1-4aa3-b69e-ab22b925bd19"},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1825,"status":"ok","timestamp":1694695175044,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"ac2ffe3e-ad0c-443e-800c-9b076ee811b4"},"outputs":[],"source":["from TTS.tts.models.glow_tts import GlowTTS\n","model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"],"id":"ac2ffe3e-ad0c-443e-800c-9b076ee811b4"},{"cell_type":"markdown","metadata":{"id":"e2832c56-889d-49a6-95b6-eb231892ecc6"},"source":["Trainer provides a generic API to train all the 🐸TTS models with all its perks like mixed-precision training, distributed training, etc."],"id":"e2832c56-889d-49a6-95b6-eb231892ecc6"},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12252,"status":"ok","timestamp":1694695193709,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"},"user_tz":180},"id":"0f609945-4fe0-4d0d-b95e-11d7bfb63ebe","outputId":"c0e7a097-992b-453c-db09-f8154d14ec25"},"outputs":[{"output_type":"stream","name":"stderr","text":[" > Training Environment:\n"," | > Backend: Torch\n"," | > Mixed precision: True\n"," | > Precision: fp16\n"," | > Current device: 0\n"," | > Num. of GPUs: 1\n"," | > Num. of CPUs: 2\n"," | > Num. of Torch Threads: 1\n"," | > Torch seed: 54321\n"," | > Torch CUDNN: True\n"," | > Torch CUDNN deterministic: False\n"," | > Torch CUDNN benchmark: False\n"," | > Torch TF32 MatMul: False\n"," > Start Tensorboard: tensorboard --logdir=tts_train_dir/run-September-14-2023_12+39PM-0000000\n","\n"," > Model has 28610257 parameters\n"]}],"source":["from trainer import Trainer, TrainerArgs\n","trainer = Trainer(\n","    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",")"],"id":"0f609945-4fe0-4d0d-b95e-11d7bfb63ebe"},{"cell_type":"markdown","metadata":{"id":"5b320831-dd83-429b-bb6a-473f9d49d321"},"source":["### AND... 3,2,1... START TRAINING 🚀🚀🚀"],"id":"5b320831-dd83-429b-bb6a-473f9d49d321"},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4c07f99-3d1d-4bea-801e-9f33bbff0e9f","outputId":"096f1661-42c9-40a6-b6ac-81544e8c5424","executionInfo":{"status":"ok","timestamp":1694696227269,"user_tz":180,"elapsed":1004853,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","\u001b[4m\u001b[1m > EPOCH: 0/1\u001b[0m\n"," --> tts_train_dir/run-September-14-2023_12+39PM-0000000\n"]},{"output_type":"stream","name":"stdout","text":["[*] Pre-computing phonemes...\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 4/12969 [00:00<44:18,  4.88it/s]"]},{"output_type":"stream","name":"stdout","text":["ɪnstɛd əv weɪtɪŋ ðɛɹ, ɔzwɔld əpɛɹəntli wɛnt æz fɑɹ əweɪ æz hi kʊd ænd bɔɹdɪd ðə fɚst oʊk klɪf bʌs wɪt͡ʃ keɪm əlɔŋ\n"," [!] Character '͡' not found in the vocabulary. Discarding it.\n"]},{"output_type":"stream","name":"stderr","text":[" 16%|█▌        | 2059/12969 [01:39<05:43, 31.74it/s]"]},{"output_type":"stream","name":"stdout","text":["ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n"," [!] Character '“' not found in the vocabulary. Discarding it.\n","ɪntu ðə “kɹeɪtɚ” dʌɡ aʊt ɪn ðə mɪdəl, pɔɹ ðə spʌnd͡ʒ, wɔɹm wɔtɚ, ðə məlæsɪz, ænd soʊdə dɪzɑlvd ɪn hɑt wɔtɚ.\n"," [!] Character '”' not found in the vocabulary. Discarding it.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 12969/12969 [06:25<00:00, 33.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","> DataLoader initialization\n","| > Tokenizer:\n","\t| > add_blank: False\n","\t| > use_eos_bos: False\n","\t| > use_phonemes: True\n","\t| > phonemizer:\n","\t\t| > phoneme language: en-us\n","\t\t| > phoneme backend: gruut\n","\t| > 3 not found characters:\n","\t| > ͡\n","\t| > “\n","\t| > ”\n","| > Number of instances : 12969\n"," | > Preprocessing samples\n"," | > Max text length: 188\n"," | > Min text length: 13\n"," | > Avg text length: 100.90014650319993\n"," | \n"," | > Max audio length: 222643.0\n"," | > Min audio length: 24499.0\n"," | > Avg audio length: 144984.29755570978\n"," | > Num. instances discarded samples: 0"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\n","\u001b[1m > TRAINING (2023-09-14 12:46:47) \u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n"," | > Batch group size: 0.\n"]},{"output_type":"stream","name":"stderr","text":["\n","\u001b[1m   --> TIME: 2023-09-14 12:47:02 -- STEP: 0/406 -- GLOBAL_STEP: 0\u001b[0m\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 12.0681  (12.068134069442749)\n","     | > loader_time: 3.5271  (3.5270605087280273)\n","\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n"," [!] `train_step()` retuned `None` outputs. Skipping training step.\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:47:24 -- STEP: 25/406 -- GLOBAL_STEP: 25\u001b[0m\n","     | > loss: 3.469851493835449  (3.3262609481811523)\n","     | > log_mle: 0.7599165439605713  (0.7566794236501058)\n","     | > loss_dur: 2.709934949874878  (2.5695815563201903)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(9.0666, device='cuda:0')  (tensor(8.2275, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.0741  (0.8438456916809082)\n","     | > loader_time: 0.0247  (7.353933601379395)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:47:48 -- STEP: 50/406 -- GLOBAL_STEP: 50\u001b[0m\n","     | > loss: 3.349116563796997  (3.3109758317470552)\n","     | > log_mle: 0.7586314082145691  (0.7581751480698585)\n","     | > loss_dur: 2.590485095977783  (2.552800685167313)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.8331, device='cuda:0')  (tensor(8.5809, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.3549  (0.8921218442916871)\n","     | > loader_time: 0.0251  (3.6840658235549917)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:48:14 -- STEP: 75/406 -- GLOBAL_STEP: 75\u001b[0m\n","     | > loss: 3.382378101348877  (3.3094464008624738)\n","     | > log_mle: 0.7662323713302612  (0.7586445001455454)\n","     | > loss_dur: 2.6161458492279053  (2.5508018970489506)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.9493, device='cuda:0')  (tensor(8.6750, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.852  (0.9322889741261801)\n","     | > loader_time: 0.0055  (2.4603884061177563)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:48:41 -- STEP: 100/406 -- GLOBAL_STEP: 100\u001b[0m\n","     | > loss: 3.2870216369628906  (3.3055526415506997)\n","     | > log_mle: 0.7637887597084045  (0.7588712871074677)\n","     | > loss_dur: 2.523232936859131  (2.546681356430053)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.7752, device='cuda:0')  (tensor(8.7119, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.8989  (0.9665101599693299)\n","     | > loader_time: 0.0055  (1.8491932916641232)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:49:12 -- STEP: 125/406 -- GLOBAL_STEP: 125\u001b[0m\n","     | > loss: 3.3427517414093018  (3.304713147619496)\n","     | > log_mle: 0.7641311287879944  (0.7588462565256202)\n","     | > loss_dur: 2.578620672225952  (2.545866893685382)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.9001, device='cuda:0')  (tensor(8.7351, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.4384  (1.0150605144500735)\n","     | > loader_time: 0.0207  (1.4823714714050291)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:49:43 -- STEP: 150/406 -- GLOBAL_STEP: 150\u001b[0m\n","     | > loss: 3.2885756492614746  (3.3057999866349355)\n","     | > log_mle: 0.7601591348648071  (0.7588449959244046)\n","     | > loss_dur: 2.528416633605957  (2.5469549928392676)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.7968, device='cuda:0')  (tensor(8.7500, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.1128  (1.0518580961227424)\n","     | > loader_time: 0.0162  (1.2385460964838664)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:50:15 -- STEP: 175/406 -- GLOBAL_STEP: 175\u001b[0m\n","     | > loss: 3.2731118202209473  (3.3031647841135663)\n","     | > log_mle: 0.758793294429779  (0.7587726235389709)\n","     | > loss_dur: 2.5143184661865234  (2.5443921623807957)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.7105, device='cuda:0')  (tensor(8.7504, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.8298  (1.0806805610656751)\n","     | > loader_time: 0.0054  (1.0638349165235244)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:50:52 -- STEP: 200/406 -- GLOBAL_STEP: 200\u001b[0m\n","     | > loss: 3.2648820877075195  (3.302728605270386)\n","     | > log_mle: 0.7614694833755493  (0.7587916556157563)\n","     | > loss_dur: 2.5034127235412598  (2.543936951536881)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.7308, device='cuda:0')  (tensor(8.7529, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 0.948  (1.124400079250337)\n","     | > loader_time: 0.015  (0.9331886494159696)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:51:29 -- STEP: 225/406 -- GLOBAL_STEP: 225\u001b[0m\n","     | > loss: 3.291504144668579  (3.2998207147731335)\n","     | > log_mle: 0.7569699883460999  (0.758879180009975)\n","     | > loss_dur: 2.534534215927124  (2.5409415389216212)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.7294, device='cuda:0')  (tensor(8.7476, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.9892  (1.1632463232676202)\n","     | > loader_time: 0.0323  (0.8319963730706107)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:52:07 -- STEP: 250/406 -- GLOBAL_STEP: 250\u001b[0m\n","     | > loss: 3.3034307956695557  (3.3001643349726995)\n","     | > log_mle: 0.7616734504699707  (0.7589929985503355)\n","     | > loss_dur: 2.541757345199585  (2.541171342134475)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.6449, device='cuda:0')  (tensor(8.7479, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.5256  (1.1934324674606336)\n","     | > loader_time: 0.0321  (0.7510216436386106)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:52:48 -- STEP: 275/406 -- GLOBAL_STEP: 275\u001b[0m\n","     | > loss: 3.2888500690460205  (3.2992060031530994)\n","     | > log_mle: 0.7612718939781189  (0.7587815140778164)\n","     | > loss_dur: 2.527578115463257  (2.540424495373131)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.6554, device='cuda:0')  (tensor(8.7432, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.3449  (1.2331466874209331)\n","     | > loader_time: 0.0189  (0.6848105300556527)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:53:31 -- STEP: 300/406 -- GLOBAL_STEP: 300\u001b[0m\n","     | > loss: 3.316124677658081  (3.2981121408528304)\n","     | > log_mle: 0.7575399875640869  (0.758682314280806)\n","     | > loss_dur: 2.558584690093994  (2.5394298315048216)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.7305, device='cuda:0')  (tensor(8.7358, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.3548  (1.270956798394523)\n","     | > loader_time: 0.027  (0.6294627904891965)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:54:15 -- STEP: 325/406 -- GLOBAL_STEP: 325\u001b[0m\n","     | > loss: 3.248223304748535  (3.2960674603780116)\n","     | > log_mle: 0.7584830522537231  (0.7585355813541109)\n","     | > loss_dur: 2.4897401332855225  (2.53753188072689)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.5656, device='cuda:0')  (tensor(8.7263, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.357  (1.306275681715747)\n","     | > loader_time: 0.0104  (0.5826851947490981)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:55:01 -- STEP: 350/406 -- GLOBAL_STEP: 350\u001b[0m\n","     | > loss: 3.201355457305908  (3.2958680538570184)\n","     | > log_mle: 0.7545133829116821  (0.7584492362597409)\n","     | > loss_dur: 2.4468419551849365  (2.537418819175046)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.4406, device='cuda:0')  (tensor(8.7182, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.4694  (1.341332330703737)\n","     | > loader_time: 0.0145  (0.5429436969757074)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:55:47 -- STEP: 375/406 -- GLOBAL_STEP: 375\u001b[0m\n","     | > loss: 3.3062639236450195  (3.2931119272153677)\n","     | > log_mle: 0.7527965307235718  (0.7582523893003594)\n","     | > loss_dur: 2.5534675121307373  (2.5348595390581092)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.5888, device='cuda:0')  (tensor(8.7048, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.2963  (1.3743724848429377)\n","     | > loader_time: 0.0076  (0.5086061172485344)\n","\n","\n","\u001b[1m   --> TIME: 2023-09-14 12:56:35 -- STEP: 400/406 -- GLOBAL_STEP: 400\u001b[0m\n","     | > loss: 3.252135753631592  (3.2902464102476077)\n","     | > log_mle: 0.7547762393951416  (0.7581529495043632)\n","     | > loss_dur: 2.49735951423645  (2.532093461965902)\n","     | > amp_scaler: 16384.0  (16384.0)\n","     | > grad_norm: tensor(8.4480, device='cuda:0')  (tensor(8.6900, device='cuda:0'))\n","     | > current_lr: 2.5e-07 \n","     | > step_time: 1.0133  (1.4052957093715681)\n","     | > loader_time: 0.0066  (0.47824029505252774)\n","\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","> DataLoader initialization\n","| > Tokenizer:\n","\t| > add_blank: False\n","\t| > use_eos_bos: False\n","\t| > use_phonemes: True\n","\t| > phonemizer:\n","\t\t| > phoneme language: en-us\n","\t\t| > phoneme backend: gruut\n","\t| > 3 not found characters:\n","\t| > ͡\n","\t| > “\n","\t| > ”\n","| > Number of instances : 131\n"," | > Preprocessing samples\n"," | > Max text length: 174\n"," | > Min text length: 20\n"," | > Avg text length: 100.76335877862596\n"," | \n"," | > Max audio length: 222643.0\n"," | > Min audio length: 34739.0\n"," | > Avg audio length: 144033.41221374046\n"," | > Num. instances discarded samples: 0\n"," | > Batch group size: 0.\n"," | > Synthesizing test sentences.\n"]},{"output_type":"stream","name":"stderr","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time: 0.010036945343017578 \u001b[0m(+0)\n","     | > avg_loss: 3.2399744391441345 \u001b[0m(+0)\n","     | > avg_log_mle: 0.7539374753832817 \u001b[0m(+0)\n","     | > avg_loss_dur: 2.486036956310272 \u001b[0m(+0)\n","\n"," > BEST MODEL : tts_train_dir/run-September-14-2023_12+39PM-0000000/best_model_406.pth\n"]}],"source":["trainer.fit()"],"id":"d4c07f99-3d1d-4bea-801e-9f33bbff0e9f"},{"cell_type":"markdown","metadata":{"id":"4cff0c40-2734-40a6-a905-e945a9fb3e98"},"source":["#### 🚀 Run the Tensorboard. 🚀\n","On the notebook and Tensorboard, you can monitor the progress of your model. Also Tensorboard provides certain figures and sample outputs."],"id":"4cff0c40-2734-40a6-a905-e945a9fb3e98"},{"cell_type":"code","source":["import locale\n","print(locale.getpreferredencoding())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0pN5T7vn4e6","executionInfo":{"status":"ok","timestamp":1694696326848,"user_tz":180,"elapsed":232,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}},"outputId":"20633fe5-879e-4b3b-ad32-34d86acecfa4"},"id":"w0pN5T7vn4e6","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["ANSI_X3.4-1968\n"]}]},{"cell_type":"code","source":["import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"],"metadata":{"id":"rAx4lyePoATW","executionInfo":{"status":"ok","timestamp":1694696328671,"user_tz":180,"elapsed":235,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"id":"rAx4lyePoATW","execution_count":13,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-wxNbUeyyj7Q"},"id":"-wxNbUeyyj7Q","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"5a85cd3b-1646-40ad-a6c2-49323e08eeec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694696485144,"user_tz":180,"elapsed":154771,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}},"outputId":"c2ddad2a-6941-4ba1-ad54-d190588329d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.13.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.57.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.4)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.0)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.7)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.41.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n","\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m2023-09-14 12:59:00.059681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\n","NOTE: Using experimental fast data loading logic. To disable, pass\n","    \"--load_fast=false\" and report issues on GitHub. More details:\n","    https://github.com/tensorflow/tensorboard/issues/4784\n","\n","Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n","TensorBoard 2.13.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"]}],"source":["!pip install tensorboard\n","!tensorboard --logdir=tts_train_dir"],"id":"5a85cd3b-1646-40ad-a6c2-49323e08eeec"},{"cell_type":"markdown","metadata":{"id":"9f6dc959"},"source":["## ✅ Test the model\n","\n","We made it! 🙌\n","\n","Let's kick off the testing run, which displays performance metrics.\n","\n","We're committing the cardinal sin of ML 😈 (aka - testing on our training data) so you don't want to deploy this model into production. In this notebook we're focusing on the workflow itself, so it's forgivable 😇\n","\n","You can see from the test output that our tiny model has overfit to the data, and basically memorized this one sentence.\n","\n","When you start training your own models, make sure your testing data doesn't include your training data 😅"],"id":"9f6dc959"},{"cell_type":"markdown","metadata":{"id":"99fada7a-592f-4a09-9369-e6f3d82de3a0"},"source":["Let's get the latest saved checkpoint."],"id":"99fada7a-592f-4a09-9369-e6f3d82de3a0"},{"cell_type":"code","execution_count":15,"metadata":{"id":"6dd47ed5-da8e-4bf9-b524-d686630d6961","executionInfo":{"status":"ok","timestamp":1694696839759,"user_tz":180,"elapsed":253,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"outputs":[],"source":["import glob, os\n","output_path = \"tts_train_dir\"\n","ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n","configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"],"id":"6dd47ed5-da8e-4bf9-b524-d686630d6961"},{"cell_type":"code","source":["!export LC_ALL=en_US.UTF-8\n","!export LANG=en_US.UTF-8\n"],"metadata":{"id":"fCcNAMSHnfNf","executionInfo":{"status":"ok","timestamp":1694696842968,"user_tz":180,"elapsed":273,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}}},"id":"fCcNAMSHnfNf","execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"dd42bc7a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694698023123,"user_tz":180,"elapsed":7784,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}},"outputId":"6d3006bb-b7bb-4a9b-c1a8-3234cb0a857b"},"outputs":[{"output_type":"stream","name":"stdout","text":["usage: tts\n","       [-h]\n","       [--list_models [LIST_MODELS]]\n","       [--model_info_by_idx MODEL_INFO_BY_IDX]\n","       [--model_info_by_name MODEL_INFO_BY_NAME]\n","       [--text TEXT]\n","       [--model_name MODEL_NAME]\n","       [--vocoder_name VOCODER_NAME]\n","       [--config_path CONFIG_PATH]\n","       [--model_path MODEL_PATH]\n","       [--out_path OUT_PATH]\n","       [--use_cuda USE_CUDA]\n","       [--device DEVICE]\n","       [--vocoder_path VOCODER_PATH]\n","       [--vocoder_config_path VOCODER_CONFIG_PATH]\n","       [--encoder_path ENCODER_PATH]\n","       [--encoder_config_path ENCODER_CONFIG_PATH]\n","       [--cs_model CS_MODEL]\n","       [--emotion EMOTION]\n","       [--language LANGUAGE]\n","       [--speakers_file_path SPEAKERS_FILE_PATH]\n","       [--language_ids_file_path LANGUAGE_IDS_FILE_PATH]\n","       [--speaker_idx SPEAKER_IDX]\n","       [--language_idx LANGUAGE_IDX]\n","       [--speaker_wav SPEAKER_WAV [SPEAKER_WAV ...]]\n","       [--gst_style GST_STYLE]\n","       [--capacitron_style_wav CAPACITRON_STYLE_WAV]\n","       [--capacitron_style_text CAPACITRON_STYLE_TEXT]\n","       [--list_speaker_idxs [LIST_SPEAKER_IDXS]]\n","       [--list_language_idxs [LIST_LANGUAGE_IDXS]]\n","       [--save_spectogram SAVE_SPECTOGRAM]\n","       [--reference_wav REFERENCE_WAV]\n","       [--reference_speaker_idx REFERENCE_SPEAKER_IDX]\n","       [--progress_bar PROGRESS_BAR]\n","       [--source_wav SOURCE_WAV]\n","       [--target_wav TARGET_WAV]\n","       [--voice_dir VOICE_DIR]\n","tts: error: argument --model_path: expected one argument\n"]}],"source":["!tts --text \"Text for TTS\" \\\n","      --model_path $test_ckpt \\\n","      --config_path $test_config \\\n","      --out_path out.wav"],"id":"dd42bc7a"},{"cell_type":"markdown","metadata":{"id":"81cbcb3f-d952-469b-a0d8-8941cd7af670"},"source":["## 📣 Listen to the synthesized wave 📣"],"id":"81cbcb3f-d952-469b-a0d8-8941cd7af670"},{"cell_type":"code","execution_count":23,"metadata":{"id":"e0000bd6-6763-4a10-a74d-911dd08ebcff","colab":{"base_uri":"https://localhost:8080/","height":581},"executionInfo":{"status":"error","timestamp":1694697995286,"user_tz":180,"elapsed":706,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}},"outputId":"e014657d-ca73-4744-fac7-4c05d84ed2c4"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-23-f615633edb7b>:5: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio_data, sample_rate = librosa.load(\"out.wav\", sr=22050)\n","/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'out.wav': System error.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-f615633edb7b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Carregue o arquivo de áudio e especifique a taxa de amostragem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Crie e exiba o objeto Audio.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 )\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-119>\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         )\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'out.wav'"]}],"source":["import librosa\n","from IPython.display import Audio\n","\n","# Carregue o arquivo de áudio e especifique a taxa de amostragem.\n","audio_data, sample_rate = librosa.load(\"out.wav\", sr=22050)\n","\n","# Crie e exiba o objeto Audio.\n","audio = Audio(data=audio_data, rate=sample_rate)\n","audio"],"id":"e0000bd6-6763-4a10-a74d-911dd08ebcff"},{"cell_type":"code","source":["from IPython.display import Audio\n","\n","# Substitua 'data' pela sua matriz de amostras de áudio e 'rate' pela taxa de amostragem real.\n","audio = Audio(data=\"out.wav\", rate=22050)\n","\n","# Exiba o áudio.\n","audio\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"rqr6v7OnozSw","executionInfo":{"status":"error","timestamp":1694660579395,"user_tz":180,"elapsed":389,"user":{"displayName":"Carlos Dutra","userId":"07929477008493616021"}},"outputId":"d90c5429-c3ae-4fdc-cd7d-b8bbb08770c5"},"id":"rqr6v7OnozSw","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-309e297bbd9b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Substitua 'data' pela sua matriz de amostras de áudio e 'rate' pela taxa de amostragem real.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"out.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Exiba o áudio.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rate must be specified when data is a numpy array or list of audio samples.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m_make_wav\u001b[0;34m(data, rate, normalize)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mscaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_and_normalize_with_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mscaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_and_normalize_without_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m_validate_and_normalize_with_numpy\u001b[0;34m(data, normalize)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mnchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'out.wav'"]}]},{"cell_type":"markdown","metadata":{"id":"13914401-cad1-494a-b701-474e52829138"},"source":["## 🎉 Congratulations! 🎉 You now have trained your first TTS model!\n","Follow up with the next tutorials to learn more advanced material."],"id":"13914401-cad1-494a-b701-474e52829138"},{"cell_type":"code","execution_count":null,"metadata":{"id":"950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"},"outputs":[],"source":[],"id":"950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}